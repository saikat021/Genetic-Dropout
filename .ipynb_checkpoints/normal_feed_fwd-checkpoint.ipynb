{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import time \n",
    "from torchvision import datasets ,transforms\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import time \n",
    "from torchvision import datasets ,transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn \n",
    "from torch.nn.functional import relu ,softmax \n",
    "import copy \n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn \n",
    "from torch.nn.functional import relu ,softmax \n",
    "import copy \n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform=transforms.Compose ([\n",
    "                                          transforms.Resize((10,10)),\n",
    "                                          transforms.ToTensor()\n",
    "                                          \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=SummaryWriter('runs/exp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2970.0 1980.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000016C7FB3B748>\n",
      "2970\n",
      "1980\n"
     ]
    }
   ],
   "source": [
    "#60 percent 40 percent division \n",
    "assam_digits_datasets=datasets.ImageFolder('assame digit',data_transform)\n",
    "train_size=len(assam_digits_datasets)*0.6\n",
    "test_size=len(assam_digits_datasets)-train_size\n",
    "print(train_size,test_size)\n",
    "assam_digits_train,assam_digits_test=torch.utils.data.random_split(assam_digits_datasets,[int (train_size),int (test_size)])\n",
    "#assam_digits_train=Subset(assam_digits_datasets,range(0,2970))\n",
    "#assam_digits_test=Subset(assam_digits_datasets,range(2970,4950))\n",
    "dataloader={'train':DataLoader(assam_digits_train,shuffle=True ,batch_size=16),\n",
    "            'val':DataLoader(assam_digits_test,shuffle=True,batch_size=16\n",
    "                            )}\n",
    "print(dataloader['train'])\n",
    "dataset_sizes={'train':len(assam_digits_train),\n",
    "               'val':len(assam_digits_test)}\n",
    "\n",
    "device=torch.device(\"cuda:0\"if torch.cuda.is_available () else \"cpu\")\n",
    "print(dataset_sizes[\"train\"])\n",
    "print (dataset_sizes[\"val\"])\n",
    "#for images,labels in dataloader[\"val\"]:\n",
    " #   print(images.shape ,type(images ),labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super (Model,self ).__init__()\n",
    "        self .linear1=nn.Linear (10*10*3,3000)\n",
    "        self.linear2=nn.Linear(3000,10)\n",
    "        self.drop_layer=nn.Dropout (p=0.4)\n",
    "        \n",
    "        \n",
    "    def Forward (self,x):\n",
    "        \n",
    "        x=x.view(-1,10*10*3)\n",
    "        act1=relu(self.linear1(x))\n",
    "        act1_mod=self.drop_layer(act1)\n",
    "       \n",
    "        act2=softmax(self.linear2(act1_mod))\n",
    "        \n",
    "        \n",
    "        return act2\n",
    "    \n",
    "    \n",
    "   \n",
    "        \n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model()#creating the object of the class\n",
    "model.to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "  # the mask has to be specified \n",
    "\n",
    "      since = time.time()\n",
    "\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "      best_acc = 0.0\n",
    "      losses=[]\n",
    "      accuracies=[]\n",
    "\n",
    "      for epoch in range(num_epochs):\n",
    "          print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "          print('-' * 10)\n",
    "\n",
    "          # Each epoch has a training and validation phase\n",
    "          for phase in ['train', 'val']:\n",
    "              if phase == 'train':\n",
    "                  \n",
    "                  model.train()  # Set model to training mode\n",
    "              else:\n",
    "\n",
    "                  model.eval()   # Set model to evaluate mode\n",
    "\n",
    "              running_loss = 0.0\n",
    "              running_corrects = 0\n",
    "\n",
    "              # Iterate over data.\n",
    "              for inputs, labels in dataloader[phase]:\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs= model.Forward(inputs)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)# backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        #print (model.linear1.weight.grad)\n",
    "                        #print (model.linear2.weight.grad)\n",
    "\n",
    "                  # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                  \n",
    "\n",
    "              epoch_loss = running_loss / dataset_sizes[phase]\n",
    "              epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "              writer.add_scalar('loss',epoch_loss,epoch)\n",
    "            \n",
    "\n",
    "              print('{} Loss: {:.4f} Acc: {:.4f} '.format(\n",
    "                  phase, epoch_loss, epoch_acc))\n",
    "\n",
    "              # deep copy the model\n",
    "              if phase == 'val' and epoch_acc > best_acc:\n",
    "                  best_acc = epoch_acc\n",
    "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "              if phase=='train':\n",
    "                losses.append(epoch_loss)\n",
    "                accuracies.append(epoch_acc)\n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "      time_elapsed = time.time() - since\n",
    "      print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "          time_elapsed // 60, time_elapsed % 60))\n",
    "      print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "      # load best model weights\n",
    "      model.load_state_dict(best_model_wts)\n",
    "      return model,losses,accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.3014 Acc: 0.1125 \n",
      "val Loss: 2.2997 Acc: 0.0980 \n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 2.2971 Acc: 0.1461 \n",
      "val Loss: 2.2952 Acc: 0.1899 \n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 2.2888 Acc: 0.1657 \n",
      "val Loss: 2.2879 Acc: 0.1859 \n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 2.2794 Acc: 0.1926 \n",
      "val Loss: 2.2804 Acc: 0.1687 \n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 2.2704 Acc: 0.1899 \n",
      "val Loss: 2.2684 Acc: 0.1899 \n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 2.2562 Acc: 0.2098 \n",
      "val Loss: 2.2588 Acc: 0.1899 \n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 2.2441 Acc: 0.2152 \n",
      "val Loss: 2.2441 Acc: 0.1919 \n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 2.2315 Acc: 0.2357 \n",
      "val Loss: 2.2326 Acc: 0.1939 \n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 2.2172 Acc: 0.2586 \n",
      "val Loss: 2.2177 Acc: 0.2040 \n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 2.2042 Acc: 0.3017 \n",
      "val Loss: 2.2041 Acc: 0.2970 \n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 2.1871 Acc: 0.3411 \n",
      "val Loss: 2.1899 Acc: 0.3182 \n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 2.1743 Acc: 0.3677 \n",
      "val Loss: 2.1795 Acc: 0.2955 \n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 2.1591 Acc: 0.4138 \n",
      "val Loss: 2.1618 Acc: 0.3581 \n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 2.1432 Acc: 0.4165 \n",
      "val Loss: 2.1414 Acc: 0.4616 \n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 2.1287 Acc: 0.4478 \n",
      "val Loss: 2.1274 Acc: 0.4480 \n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 2.1100 Acc: 0.4623 \n",
      "val Loss: 2.1135 Acc: 0.4571 \n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 2.0966 Acc: 0.4667 \n",
      "val Loss: 2.0998 Acc: 0.4490 \n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 2.0824 Acc: 0.4751 \n",
      "val Loss: 2.0861 Acc: 0.4687 \n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 2.0704 Acc: 0.4774 \n",
      "val Loss: 2.0747 Acc: 0.4697 \n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 2.0580 Acc: 0.4828 \n",
      "val Loss: 2.0624 Acc: 0.4687 \n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 2.0483 Acc: 0.4875 \n",
      "val Loss: 2.0536 Acc: 0.4707 \n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 2.0367 Acc: 0.4923 \n",
      "val Loss: 2.0452 Acc: 0.4707 \n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 2.0299 Acc: 0.4886 \n",
      "val Loss: 2.0399 Acc: 0.4626 \n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 2.0219 Acc: 0.4919 \n",
      "val Loss: 2.0331 Acc: 0.4737 \n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 2.0144 Acc: 0.4933 \n",
      "val Loss: 2.0244 Acc: 0.4727 \n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 2.0091 Acc: 0.4960 \n",
      "val Loss: 2.0201 Acc: 0.4737 \n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 2.0053 Acc: 0.4929 \n",
      "val Loss: 2.0181 Acc: 0.4707 \n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 1.9997 Acc: 0.4943 \n",
      "val Loss: 2.0119 Acc: 0.4732 \n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 1.9955 Acc: 0.4963 \n",
      "val Loss: 2.0083 Acc: 0.4742 \n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 1.9899 Acc: 0.4990 \n",
      "val Loss: 2.0038 Acc: 0.4732 \n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 1.9845 Acc: 0.4997 \n",
      "val Loss: 1.9970 Acc: 0.4742 \n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 1.9780 Acc: 0.5044 \n",
      "val Loss: 1.9909 Acc: 0.4955 \n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 1.9732 Acc: 0.5249 \n",
      "val Loss: 1.9845 Acc: 0.5409 \n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 1.9681 Acc: 0.5414 \n",
      "val Loss: 1.9784 Acc: 0.5460 \n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 1.9617 Acc: 0.5569 \n",
      "val Loss: 1.9744 Acc: 0.5247 \n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 1.9568 Acc: 0.5596 \n",
      "val Loss: 1.9662 Acc: 0.5515 \n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 1.9502 Acc: 0.5670 \n",
      "val Loss: 1.9619 Acc: 0.5470 \n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 1.9444 Acc: 0.5724 \n",
      "val Loss: 1.9552 Acc: 0.5611 \n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 1.9382 Acc: 0.5737 \n",
      "val Loss: 1.9488 Acc: 0.5561 \n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 1.9322 Acc: 0.5788 \n",
      "val Loss: 1.9411 Acc: 0.5611 \n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 1.9255 Acc: 0.5909 \n",
      "val Loss: 1.9329 Acc: 0.6005 \n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 1.9172 Acc: 0.6185 \n",
      "val Loss: 1.9270 Acc: 0.6177 \n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 1.9104 Acc: 0.6286 \n",
      "val Loss: 1.9193 Acc: 0.6015 \n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 1.9043 Acc: 0.6397 \n",
      "val Loss: 1.9135 Acc: 0.6273 \n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 1.8970 Acc: 0.6478 \n",
      "val Loss: 1.9034 Acc: 0.6591 \n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 1.8875 Acc: 0.6613 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-612b72890a71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-eebcb4ce3615>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m               \u001b[1;31m# Iterate over data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m               \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m    137\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2806\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2808\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_core\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2810\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m_open_core\u001b[1;34m(fp, filename, prefix)\u001b[0m\n\u001b[0;32m   2792\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2793\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2794\u001b[1;33m                     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2795\u001b[0m                     \u001b[0m_decompression_bomb_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2796\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fp, filename)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         except (\n\u001b[0;32m    107\u001b[0m             \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# end of data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\PngImagePlugin.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;31m# get next chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mcid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\PngImagePlugin.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mcid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model,losses,accuracies=train_model(model,criterion,optimizer,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population:\n",
    "    \n",
    "    def __init__(self,m,num,maskLength):\n",
    "        # constructor for initialising the population list\n",
    "        #list of DNA objects\n",
    "        self.population=[]\n",
    "        #muation rate for mutation\n",
    "        self.mutation_rate=m\n",
    "        #maximum number of entities in the population\n",
    "        self.popmax=num\n",
    "\n",
    "        self.maskLength=maskLength\n",
    "        for i in range (num):\n",
    "            #creating a dna object\n",
    "            #an initial random population created \n",
    "            dna =DNA(self.maskLength)\n",
    "            self.population.append (dna)\n",
    "      \n",
    "        self.matingPool=[]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calcFitness (self,model):\n",
    "        # going through all the entities of population \n",
    "        #finding fitness of all population entities \n",
    "        for i in range(0,self.popmax):\n",
    "            self.population[i].fitness (model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def naturalSelection(self):\n",
    "        self.matingPool=[]\n",
    "        maxFitness=0\n",
    "        for i in range (self.popmax):\n",
    "            # moving throught the entire population \n",
    "            if (self.population[i].fit>maxFitness):\n",
    "                maxFitness=self.population[i].fit\n",
    "       \n",
    "        # max Fitness has the maximum loss score of the entire population  \n",
    "        for i in range (self.popmax ):\n",
    "        # iterating through the all inviduals of the population\n",
    "            n=self.Mymap(self.population[i].fit,0,maxFitness,0,1)\n",
    "        \n",
    "            n=math.floor(n*100)\n",
    "            \n",
    "            for j in range (n):\n",
    "                #creating mating pool\n",
    "                self.matingPool.append (self.population[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def Mymap(self,num,prevlow,prevhigh,nextlow,nexthigh):\n",
    "        \n",
    "        prevrange =float((num-prevlow)/(prevhigh-prevlow))\n",
    "        return nextlow+(nexthigh-nextlow)*prevrange\n",
    "\n",
    "\n",
    "\n",
    "    def   generate (self):\n",
    "        for i in range (self.popmax ):\n",
    "            index_1=math.floor(random.randint  (0,len(self.matingPool)-1))\n",
    "            index_2=math.floor (random.randint (0,len(self.matingPool)-1))\n",
    "            parent1=self.matingPool[index_1]\n",
    "            parent2=self.matingPool[index_2]\n",
    "            child=parent1.crossover(parent2)\n",
    "            child.mutate(self.mutation_rate)\n",
    "            self.population[i]=child \n",
    "\n",
    "\n",
    "    def fittest(self):\n",
    "        #returns the fiitest individual mask of the population \n",
    "        #also returns the keeping probability of the fittest mask \n",
    "        fittest=self.population[0]\n",
    "        for i  in range (self.popmax):\n",
    "            if (fittest.fit<self.population[i].fit):\n",
    "                fittest=self.population[i]\n",
    "        return fittest,fittest.keep_prob()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class DNA:\n",
    "    \n",
    "    \n",
    "    def __init__(self,maskLength):\n",
    "        #constructor for the creation of the mask as a gene object \n",
    "        self.maskLength=maskLength\n",
    "        #creation of mask \n",
    "        self.gene=torch.bernoulli(torch.empty(1,maskLength).uniform_(0,1))\n",
    "        self.fit=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def keep_prob (self):\n",
    "\n",
    "        num_one =0\n",
    "        for i in range (self.maskLength):\n",
    "            if (self.gene[0,i]==1):\n",
    "                num_one=num_one+1\n",
    "        return float(num_one/self.maskLength)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fitness(self,model):\n",
    "        # finding the fitness of a particular mask\n",
    "        #accuracy of all training set is the fitness in one epoch\n",
    "        #putting model in train mode \n",
    "        running_loss=0\n",
    "        model.train()\n",
    "        \n",
    "        for inputs,labels in dataloader ['train']:\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device )\n",
    "            outputs=model.Forward(inputs,self.gene,self.keep_prob())\n",
    "            _,preds=torch.max(outputs,1)\n",
    "            loss=criterion (outputs,labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / dataset_sizes['train']\n",
    "        \n",
    "        self.fit=epoch_loss\n",
    "        return epoch_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def crossover (self,parent2):\n",
    "        #one parent is the passed in the argument \n",
    "        #another parent is the one from which this function is called \n",
    "        #another parent is self.gene\n",
    "        child =DNA(self.maskLength)\n",
    "        midpoint =random .randint (0,self.maskLength-1)\n",
    "        for i in range (0,self.maskLength):\n",
    "            if (i>midpoint):\n",
    "                child.gene [0,i]=self.gene[0,i]\n",
    "            else :\n",
    "                child.gene [0,i]=parent2.gene[0,i]\n",
    "        \n",
    "        return child \n",
    "\n",
    "    def mutate(self,mutation_rate):\n",
    "        #randomly activate some of the nodes  \n",
    "        #mutate some of the genes \n",
    "        for i in range (self.maskLength):\n",
    "            if (random.randint (0,99)<=mutation_rate*100):\n",
    "                self.gene[0,i]=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_rate =0.01\n",
    "max_population=40\n",
    "maskLength=2500\n",
    "model=Model()#creating the object of the class\n",
    "model.to(device)\n",
    "model.apply(weights_init)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control block controls the epochs and the generations of mask\n",
    "#step 1 an object of the population class randomly generating the first population \n",
    "#step2 :calculate fitness of each entitiy of the population \n",
    "#step3: creates a mating pool of the population based on the worst two performing parent \n",
    "#step 4 :fittest mask of the generating along with keep_prob found \n",
    "#step 5: if 0th ,10th ,20th, the epochs starts training on the worst performing mask /other wise new generation is created \n",
    "\n",
    "epochgens=0\n",
    "population =Population(mutation_rate,max_population,maskLength)\n",
    "\n",
    "while (epochgens<100):\n",
    "    print ('Epoch generations (',epochgens,'/100)',end=' :')\n",
    "    population .calcFitness(model)\n",
    "    population.naturalSelection()\n",
    "    fittestmask,p=population .fittest()\n",
    "    loss=fittestmask.fitness(model)\n",
    "    print (\"loss (fittest mask)\",loss,end='\\n')\n",
    "    if (epochgens%10==0):\n",
    "        model,losses,accuracies=train_model(model,criterion,optimizer,fittestmask.gene,p,20)\n",
    "    population.generate()\n",
    "    epochgens+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
