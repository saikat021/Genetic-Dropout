{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import time \n",
    "from torchvision import datasets ,transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn \n",
    "from torch.nn.functional import relu ,softmax \n",
    "import copy \n",
    "from torch.utils.data import Subset\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform=transforms.Compose ([transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "134\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class light_source_dataset(Dataset):\n",
    "    def __init__(self,path,transform):\n",
    "        self.df_data=pd.read_csv(path)\n",
    "        self.df_data['Classifier'] = pd.Categorical(pd.factorize(self.df_data['Classifier'])[0])\n",
    "        self.labels=np.asarray(self.df_data.iloc[:,self.df_data.shape[1]-1])\n",
    "        self.image_as_np=np.asarray(self.df_data.iloc[:,0:self.df_data.shape[1]-1]).astype('uint8')\n",
    "        self.trans=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df_data.index)\n",
    "    def __getitem__(self,index):\n",
    "        image_np=self.image_as_np[index,:,None]\n",
    "       \n",
    "        pillow_image=Image.fromarray(image_np.astype('uint8'))\n",
    "        \n",
    "        single_label=self.labels[index]\n",
    "        if (self.trans is not None):\n",
    "            img_as_tensor=self.trans(pillow_image)\n",
    "        \n",
    "        \n",
    "            \n",
    "        return (img_as_tensor,single_label)\n",
    "        \n",
    "dataset=light_source_dataset('gabor/gabor_jaffe_32_640.csv',data_transform)\n",
    "print(len(dataset))\n",
    "train_size=int (len(dataset)*0.6)\n",
    "test_size=len(dataset)-train_size\n",
    "trainloader=DataLoader(dataset,batch_size=1)\n",
    "\n",
    "train_data,test_data=torch.utils.data.random_split(dataset,[int (train_size), int (test_size)])\n",
    "dataloader={'train':DataLoader(train_data,shuffle=False ,batch_size=1),\n",
    "            'val':DataLoader(test_data,shuffle=False,batch_size=1\n",
    "                            )}\n",
    "\n",
    "dataset_sizes={'train':len(train_data),\n",
    "               'val':len(test_data)}\n",
    "\n",
    "device=torch.device(\"cuda:0\"if torch.cuda.is_available () else \"cpu\")\n",
    "print(dataset_sizes[\"train\"])\n",
    "print (dataset_sizes[\"val\"])\n",
    "\n",
    " \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super (Model,self ).__init__()\n",
    "        self .linear1=nn.Linear (640,3000)\n",
    "        self.linear2=nn.Linear (3000,7)\n",
    "        \n",
    "    def Forward (self,x,mask,p):\n",
    "        #feed forward function \n",
    "        x=x.view(-1,640)\n",
    "        act1=relu(self.linear1(x))\n",
    "        act1_masked =self.masking (act1,mask,p)\n",
    "        act2=softmax(self.linear2(act1_masked ))\n",
    "        return act2\n",
    "    \n",
    "    \n",
    "    \n",
    "    def masking (self,act1,mask,p):\n",
    "        if (self.training ==True ):\n",
    "            return ((act1*mask)/p)\n",
    "        else :\n",
    "            return (act1)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model()#creating the object of the class\n",
    "model.to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer,mask,p, num_epochs=25):\n",
    "  # the mask has to be specified \n",
    "\n",
    "      mask=torch.from_numpy(mask)\n",
    "      since = time.time()\n",
    "\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "      best_acc = 0.0\n",
    "      losses=[]\n",
    "      accuracies=[]\n",
    "\n",
    "      for epoch in range(num_epochs):\n",
    "          print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "          print('-' * 10)\n",
    "\n",
    "          # Each epoch has a training and validation phase\n",
    "          for phase in ['train', 'val']:\n",
    "              if phase == 'train':\n",
    "                  \n",
    "                  model.train()  # Set model to training mode\n",
    "              else:\n",
    "\n",
    "                  model.eval()   # Set model to evaluate mode\n",
    "\n",
    "              running_loss = 0.0\n",
    "              running_corrects = 0\n",
    "\n",
    "              # Iterate over data.\n",
    "              for inputs, labels in dataloader[phase]:\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs= model.Forward(inputs,mask,p)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)# backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        #print (model.linear1.weight.grad)\n",
    "                        #print (model.linear2.weight.grad)\n",
    "\n",
    "                  # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                  \n",
    "\n",
    "              epoch_loss = running_loss / dataset_sizes[phase]\n",
    "              epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "\n",
    "              print('{} Loss: {:.4f} Acc: {:.4f} '.format(\n",
    "                  phase, epoch_loss, epoch_acc))\n",
    "\n",
    "              # deep copy the model\n",
    "              if phase == 'val' and epoch_acc > best_acc:\n",
    "                  best_acc = epoch_acc\n",
    "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "              if phase=='train':\n",
    "                losses.append(epoch_loss)\n",
    "                accuracies.append(epoch_acc)\n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "      time_elapsed = time.time() - since\n",
    "      print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "          time_elapsed // 60, time_elapsed % 60))\n",
    "      print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "      # load best model weights\n",
    "      model.load_state_dict(best_model_wts)\n",
    "      return model,losses,accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Population:\n",
    "    \n",
    "    def __init__(self,m,num,maskLength):\n",
    "        # constructor for initialising the population list\n",
    "        #list of DNA objects\n",
    "        self.population=[]\n",
    "        #muation rate for mutation\n",
    "        self.mutation_rate=m\n",
    "        #maximum number of entities in the population\n",
    "        self.popmax=num\n",
    "\n",
    "        self.maskLength=maskLength\n",
    "        for i in range (num):\n",
    "            #creating a dna object\n",
    "            #an initial random population created \n",
    "            dna =DNA(self.maskLength)\n",
    "            self.population.append (dna)\n",
    "      \n",
    "        self.matingPool=[]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calcFitness (self,model):\n",
    "        # going through all the entities of population \n",
    "        #finding fitness of all population entities \n",
    "        for i in range(0,self.popmax):\n",
    "            self.population[i].fitness (model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def naturalSelection(self):\n",
    "        self.matingPool=[]\n",
    "        maxFitness=0\n",
    "        for i in range (self.popmax):\n",
    "            # moving throught the entire population \n",
    "            if (self.population[i].fit>maxFitness):\n",
    "                maxFitness=self.population[i].fit\n",
    "       \n",
    "        # max Fitness has the maximum loss score of the entire population  \n",
    "        for i in range (self.popmax ):\n",
    "        # iterating through the all inviduals of the population\n",
    "            n=self.Mymap(self.population[i].fit,0,maxFitness,0,1)\n",
    "        \n",
    "            n=math.floor(n*100)\n",
    "            \n",
    "            for j in range (n):\n",
    "                #creating mating pool\n",
    "                self.matingPool.append (self.population[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def Mymap(self,num,prevlow,prevhigh,nextlow,nexthigh):\n",
    "        \n",
    "        prevrange =float((num-prevlow)/(prevhigh-prevlow))\n",
    "        return nextlow+(nexthigh-nextlow)*prevrange\n",
    "\n",
    "\n",
    "\n",
    "    def   generate (self):\n",
    "        for i in range (self.popmax ):\n",
    "            index_1=math.floor(random.randint  (0,len(self.matingPool)-1))\n",
    "            index_2=math.floor (random.randint (0,len(self.matingPool)-1))\n",
    "            parent1=self.matingPool[index_1]\n",
    "            parent2=self.matingPool[index_2]\n",
    "            child=parent1.crossover(parent2)\n",
    "            child.mutate(self.mutation_rate)\n",
    "            self.population[i]=child \n",
    "\n",
    "\n",
    "    def fittest(self):\n",
    "        #returns the fiitest individual mask of the population \n",
    "        #also returns the keeping probability of the fittest mask \n",
    "        fittest=self.population[0]\n",
    "        for i  in range (self.popmax):\n",
    "            if (fittest.fit<self.population[i].fit):\n",
    "                fittest=self.population[i]\n",
    "        return fittest,fittest.keep_prob()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class DNA:\n",
    "    \n",
    "    \n",
    "    def __init__(self,maskLength):\n",
    "        #constructor for the creation of the mask as a gene object \n",
    "        self.maskLength=maskLength\n",
    "        #creation of mask \n",
    "        self.gene=torch.bernoulli(torch.empty(1,maskLength).uniform_(0,1))\n",
    "        self.fit=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def keep_prob (self):\n",
    "\n",
    "        num_one =0\n",
    "        for i in range (self.maskLength):\n",
    "            if (self.gene[0,i]==1):\n",
    "                num_one=num_one+1\n",
    "        return float(num_one/self.maskLength)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fitness(self,model):\n",
    "        # finding the fitness of a particular mask\n",
    "        #accuracy of all training set is the fitness in one epoch\n",
    "        #putting model in train mode \n",
    "        running_loss=0\n",
    "        model.train()\n",
    "        \n",
    "        for inputs,labels in dataloader ['train']:\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device )\n",
    "            outputs=model.Forward(inputs,self.gene,self.keep_prob())\n",
    "            _,preds=torch.max(outputs,1)\n",
    "            loss=criterion (outputs,labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / dataset_sizes['train']\n",
    "        \n",
    "        self.fit=epoch_loss\n",
    "        return epoch_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def crossover (self,parent2):\n",
    "        #one parent is the passed in the argument \n",
    "        #another parent is the one from which this function is called \n",
    "        #another parent is self.gene\n",
    "        child =DNA(self.maskLength)\n",
    "        midpoint =random .randint (0,self.maskLength-1)\n",
    "        for i in range (0,self.maskLength):\n",
    "            if (i>midpoint):\n",
    "                child.gene [0,i]=self.gene[0,i]\n",
    "            else :\n",
    "                child.gene [0,i]=parent2.gene[0,i]\n",
    "        \n",
    "        return child \n",
    "\n",
    "    def mutate(self,mutation_rate):\n",
    "        #randomly activate some of the nodes  \n",
    "        #mutate some of the genes \n",
    "        for i in range (self.maskLength):\n",
    "            if (random.randint (0,99)<=mutation_rate*100):\n",
    "                self.gene[0,i]=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_rate =0.20\n",
    "max_population=30\n",
    "maskLength=3000\n",
    "model=Model()#creating the object of the class\n",
    "model.to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nepochgens=0\\npopulation =Population(mutation_rate,max_population,maskLength)\\n\\nwhile (epochgens<=200):\\n    print (\\'Epoch generations (\\',epochgens,\\'/200)\\',end=\\' :\\')\\n    population .calcFitness(model)\\n    population.naturalSelection()\\n    fittestmask,p=population .fittest()\\n    loss=fittestmask.fitness(model)\\n    print (\"loss (fittest mask)\",loss,end=\\'\\n\\')\\n    if (epochgens%10==0):\\n        model,losses,accuracies=train_model(model,criterion,optimizer,fittestmask.gene,p,30)\\n    population.generate()\\n    epochgens+=1\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#control block controls the epochs and the generations of mask\n",
    "#step 1 an object of the population class randomly generating the first population \n",
    "#step2 :calculate fitness of each entitiy of the population \n",
    "#step3: creates a mating pool of the population based on the worst two performing parent \n",
    "#step 4 :fittest mask of the generating along with keep_prob found \n",
    "#step 5: if 0th ,10th ,20th, the epochs starts training on the worst performing mask /other wise new generation is created \n",
    "\n",
    "epochgens=0\n",
    "population =Population(mutation_rate,max_population,maskLength)\n",
    "\n",
    "while (epochgens<=200):\n",
    "    print ('Epoch generations (',epochgens,'/200)',end=' :')\n",
    "    population .calcFitness(model)\n",
    "    population.naturalSelection()\n",
    "    fittestmask,p=population .fittest()\n",
    "    loss=fittestmask.fitness(model)\n",
    "    print (\"loss (fittest mask)\",loss,end='\\n')\n",
    "    if (epochgens%10==0):\n",
    "        model,losses,accuracies=train_model(model,criterion,optimizer,fittestmask.gene,p,30)\n",
    "    population.generate()\n",
    "    epochgens+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(mask):\n",
    "        # finding the fitness of a particular mask\n",
    "        #accuracy of all training set is the fitness in one epoch\n",
    "        #putting model in train mode\n",
    "        mask=torch.from_numpy(mask)\n",
    "        running_loss=0\n",
    "        model.train()\n",
    "        \n",
    "        for inputs,labels in dataloader ['train']:\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device )\n",
    "            outputs=model.Forward(inputs,mask,keep_prob(mask))\n",
    "            _,preds=torch.max(outputs,1)\n",
    "            loss=criterion (outputs,labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / dataset_sizes['train']\n",
    "        return epoch_loss\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def f(x):\n",
    "    #Higher-level method to do forward_prop in the whole swarm.\n",
    "    #Inputs:x: numpy.ndarray of shape (n_particles, dimensions) The swarm that will perform the search\n",
    "    #Returns numpy.ndarray of shape (n_particles, )  The computed loss for each particle\n",
    "    \n",
    "    \n",
    "    j = [fitness(x[i,:]) for i in range(num_particles)]\n",
    "    return np.array(j)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def keep_prob (mask):\n",
    "\n",
    "        num_one =0\n",
    "        for i in range (maskLength):\n",
    "            if (mask[i]==1):\n",
    "                num_one=num_one+1\n",
    "        return float(num_one/maskLength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'c1': 2, 'c2': 2, 'w':0.4}\n",
    "num_particles=30\n",
    "maskLength=3000\n",
    "model=Model()\n",
    "model.to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-28 19:26:14,773 - pyswarms.single.global_best - INFO - Optimize for 50 iters with {'c1': 2, 'c2': 2, 'w': 0.4}\n",
      "pyswarms.single.global_best:   0%|                                                                                |0/50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3000)\n",
      "Epoch generations ( 0 /200) :"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ana\\envs\\packt_torch\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n",
      "pyswarms.single.global_best:   2%|█▎                                                              |1/50, best_cost=1.94D:\\ana\\envs\\packt_torch\\lib\\site-packages\\pyswarms\\backend\\operators.py:66: RuntimeWarning: invalid value encountered in less\n",
      "  mask_cost = swarm.current_cost < swarm.pbest_cost\n",
      "pyswarms.single.global_best: 100%|███████████████████████████████████████████████████████████████|50/50, best_cost=1.91\n",
      "2020-03-28 20:38:04,944 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.9113615866917282, best pos: [ 1.7532286e-03  7.4392688e-01 -2.5716174e-04 ...  1.0000689e+00\n",
      "  1.0001880e+00 -5.6016421e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.7532286e-03  7.4392688e-01 -2.5716174e-04 ...  1.0000689e+00\n",
      "  1.0001880e+00 -5.6016421e-01] <class 'numpy.ndarray'> (3000,)\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 2.0462 Acc: 0.1194 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 2.0311 Acc: 0.1343 \n",
      "val Loss: 1.9970 Acc: 0.1556 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-28 20:39:19,272 - pyswarms.single.global_best - INFO - Optimize for 50 iters with {'c1': 2, 'c2': 2, 'w': 0.4}\n",
      "pyswarms.single.global_best:   0%|                                                                                |0/50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 1m 14s\n",
      "Best val Acc: 0.155556\n",
      "Epoch generations ( 1 /200) :"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|███████████████████████████████████████████████████████████████|50/50, best_cost=1.91\n",
      "2020-03-28 21:51:43,149 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.9113615866917282, best pos: [-5.7378206e-02 -8.1670827e-01 -6.2392945e-05 ...  7.0199317e-01\n",
      " -1.9817405e+00  6.6434020e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.7378206e-02 -8.1670827e-01 -6.2392945e-05 ...  7.0199317e-01\n",
      " -1.9817405e+00  6.6434020e-01] <class 'numpy.ndarray'> (3000,)\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9938 Acc: 0.1716 \n",
      "val Loss: 1.9970 Acc: 0.1556 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-28 21:52:58,525 - pyswarms.single.global_best - INFO - Optimize for 50 iters with {'c1': 2, 'c2': 2, 'w': 0.4}\n",
      "pyswarms.single.global_best:   0%|                                                                                |0/50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 1m 15s\n",
      "Best val Acc: 0.155556\n",
      "Epoch generations ( 2 /200) :"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best:   6%|███▊                                                            |3/50, best_cost=1.91"
     ]
    }
   ],
   "source": [
    "epochgens=0\n",
    "main_loss=[]\n",
    "mask_par=torch.bernoulli(torch.empty(num_particles,maskLength).uniform_(0,1)).numpy()\n",
    "print(mask_par.shape)\n",
    "optim = ps.single.GlobalBestPSO(n_particles=num_particles, dimensions=maskLength, options=options,init_pos=mask_par)\n",
    "while (epochgens<=20):\n",
    "    print ('Epoch generations (',epochgens,'/200)',end=' :')\n",
    "    cost,mask = optim.optimize(f,  iters=50)\n",
    "    print(mask,type(mask),mask.shape)\n",
    "    model,losses,accuracies=train_model(model,criterion,optimizer,mask,keep_prob(mask),30)\n",
    "    main_loss.append(losses)\n",
    "    epochgens+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
