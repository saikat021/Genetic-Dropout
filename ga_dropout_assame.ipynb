{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJ29JIAeACes"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import time \n",
    "from torchvision import datasets ,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn \n",
    "from torch.nn.functional import relu ,softmax \n",
    "import copy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PD3-aak0Bvjs",
    "outputId": "0171cbcf-710f-4421-afd1-13bcbdb400cc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\saikat\\\\Desktop\\\\dropout_GA'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HGhtqetHZ6R"
   },
   "outputs": [],
   "source": [
    "data_transform_train=transforms.Compose ([\n",
    "                                          transforms.Resize((10,10)),\n",
    "                                          transforms.ToTensor()\n",
    "                                          \n",
    "])\n",
    "data_transform_test=transforms.Compose ([\n",
    "                                          transforms .Resize((10,10)),\n",
    "                                          transforms .ToTensor()\n",
    "])\n",
    "data_transform={'train':data_transform_train,\n",
    "                'val':data_transform_test\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "aIOWe65HBtmJ",
    "outputId": "184db6b8-cbcb-4807-ba5d-6d2d0c400e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "mnist_data_train=datasets.MNIST('MNIST_data',train=True,transform=data_transform['train'] ,download=True)\n",
    "mnist_data_test=datasets.MNIST('MNIST_data',train=False ,download=True ,transform=data_transform[\"val\"])\n",
    "dataloader={'train':DataLoader(mnist_data_train,shuffle=True ,batch_size=16),\n",
    "            'val':DataLoader(mnist_data_test,shuffle=True,batch_size=16)}\n",
    "dataset_sizes={'train':len(mnist_data_train),\n",
    "               'val':len(mnist_data_test)}\n",
    "device=torch.device(\"cuda:0\"if torch.cuda.is_available () else \"cpu\")\n",
    "print(dataset_sizes[\"train\"])\n",
    "print (dataset_sizes[\"val\"])\n",
    "#for images,labels in dataloader[\"train\"]:\n",
    "  #print(images.shape ,type(images ),labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QjBtsYJFEme"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Model(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super (Model,self ).__init__()\n",
    "    self .linear1=nn.Linear (10*10,60)\n",
    "    self.linear2=nn.Linear (60,10)\n",
    "    \n",
    "    #self.drop_layer=nn.Dropout(p)\n",
    "    #the following line  is a try of a custom dropout layer \n",
    "  '''def drop_layer(activations ,mask):\n",
    "    if (activations.size==mask.size):\n",
    "      raise ValueError(\"mask size and activation size are not matching \")\n",
    "    return activations*mask\n",
    "    '''\n",
    "    \n",
    "  def Forward (self,x,mask):\n",
    "    x=x.view(-1,10*10)\n",
    "    act1=relu(self.linear1 (x))\n",
    "    #print(act1.shape)\n",
    "    act1_masked =act1*mask\n",
    "    act2=softmax(self.linear2(act1_masked ))\n",
    "    #print (act2.shape)\n",
    "    return act2\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QyRI3wnnX-m"
   },
   "outputs": [],
   "source": [
    "model=Model()#creating the object of the class\n",
    "model.to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BM1B5UTcRKic"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer,mask, num_epochs=25):\n",
    "  # the mask has to be specified \n",
    "\n",
    "      since = time.time()\n",
    "\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "      best_acc = 0.0\n",
    "      losses=[]\n",
    "      accuracies=[]\n",
    "\n",
    "      for epoch in range(num_epochs):\n",
    "          print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "          print('-' * 10)\n",
    "\n",
    "          # Each epoch has a training and validation phase\n",
    "          for phase in ['train', 'val']:\n",
    "              if phase == 'train':\n",
    "                  \n",
    "                  model.train()  # Set model to training mode\n",
    "              else:\n",
    "\n",
    "                  model.eval()   # Set model to evaluate mode\n",
    "\n",
    "              running_loss = 0.0\n",
    "              running_corrects = 0\n",
    "\n",
    "              # Iterate over data.\n",
    "              for inputs, labels in dataloader[phase]:\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs= model.Forward(inputs,mask)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)# backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        #print (model.linear1.weight.grad)\n",
    "                        #print (model.linear2.weight.grad)\n",
    "\n",
    "                  # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                  \n",
    "\n",
    "              epoch_loss = running_loss / dataset_sizes[phase]\n",
    "              epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "\n",
    "              print('{} Loss: {:.4f} Acc: {:.4f} '.format(\n",
    "                  phase, epoch_loss, epoch_acc))\n",
    "\n",
    "              # deep copy the model\n",
    "              if phase == 'val' and epoch_acc > best_acc:\n",
    "                  best_acc = epoch_acc\n",
    "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "              if phase=='train':\n",
    "                losses.append(epoch_loss)\n",
    "                accuracies.append(epoch_acc)\n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "      time_elapsed = time.time() - since\n",
    "      print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "          time_elapsed // 60, time_elapsed % 60))\n",
    "      print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "      # load best model weights\n",
    "      model.load_state_dict(best_model_wts)\n",
    "      return model,losses,accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5Z-oloeZU7r"
   },
   "outputs": [],
   "source": [
    "\n",
    "#checking whether the gradient becomes zero for zero in the mask\n",
    "\n",
    "mask=torch.bernoulli(torch.empty(1,60).uniform_(0,1)).to(device )\n",
    "#act=torch.ones ((5,4))\n",
    "#print (act)\n",
    "#print (mask)\n",
    "#mult=mask*act\n",
    "#print (mult)\n",
    "#print (mask)\n",
    "#model,losses,accuracies= train_model(model,criterion, optimizer,mask,num_epochs=1)\n",
    "#printing the gradients of that layer during the\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kAwY0S5vHjO"
   },
   "outputs": [],
   "source": [
    "class Population:\n",
    "  def __init__(self,m,num,maskLength):\n",
    "    # the model of which fitness matters is also passed\n",
    "    \n",
    "    #list of DNA objects\n",
    "    self.population=[]\n",
    "    #muation rate for mutation\n",
    "    self.mutation_rate=m\n",
    "    #maximum number of entities in the population\n",
    "    self.popmax=num\n",
    "   \n",
    "    self.maskLength=maskLength\n",
    "    #print (type(self.population))\n",
    "   \n",
    "    for i in range (num):\n",
    "      #creating a dna object \n",
    "      dna =DNA(self.maskLength)\n",
    "      self.population.append (dna)\n",
    "      #print (self.population[i].gene)\n",
    "    self.matingPool=[]\n",
    "    #  an intial random population is created \n",
    "\n",
    "    \n",
    "  \n",
    "\n",
    "  def calcFitness (self,model):\n",
    "      for i in range(0,self.popmax):# going through all the entities of population \n",
    "        #dna=DNA(self.maskLength)\n",
    "        self.population[i].fitness (model)\n",
    "        #print (\"entity\"+str(i)+\"/\"+str(self.popmax))\n",
    "        \n",
    "        \n",
    "  \n",
    "  def naturalSelection(self):\n",
    "    self.matingPool=[]\n",
    "    maxFitness=0\n",
    "    for i in range (self.popmax):# moving throught the entire population \n",
    "      #print (type (self.population[i].fit),maxFitness)\n",
    "      #print (self.population[i ].fit )\n",
    "      if (self.population[i].fit>maxFitness):\n",
    "        maxFitness=self.population[i].fit\n",
    "    # max Fitness has the maximum accuracy score of the population \n",
    "    for j in range (self.popmax ):\n",
    "      # iteratin through the all inviduals of the population\n",
    "      n=self.Mymap(self.population[i].fit,0,maxFitness,0,1)\n",
    "      n=math.floor(n*100)\n",
    "      for j in range (n):\n",
    "        self.matingPool.append (self.population[i])\n",
    "        #creating mating pool\n",
    "  \n",
    "  \n",
    "  \n",
    "  def Mymap(self,num,prevlow,prevhigh,nextlow,nexthigh):\n",
    "    prevrange =((num-prevlow).double()/(prevhigh-prevlow).double ())\n",
    "    return nextlow+(nexthigh-nextlow)*prevrange\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def   generate (self):\n",
    "    for i in range (self.popmax ):\n",
    "      index_1=math.floor(random.randint  (0,len(self.matingPool)-1))\n",
    "      index_2=math.floor (random.randint (0,len(self.matingPool)-1))\n",
    "      parent1=self.matingPool[index_1]\n",
    "      parent2=self.matingPool[index_2]\n",
    "      child=parent1.crossover(parent2)\n",
    "      child.mutate(self.mutation_rate)\n",
    "      self.population[i]=child \n",
    "    \n",
    "\n",
    "  def fittest(self):\n",
    "    fittest=self.population[0]#returns the fiitest individual mask of the population \n",
    "    for i  in range (self.popmax):\n",
    "      if (fittest.fit<self.population[i].fit):\n",
    "        fittest=self.population[i]\n",
    "    return fittest\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKyqdGP9vHhr"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class DNA:\n",
    "  def __init__(self,maskLength):\n",
    "    self.maskLength=maskLength\n",
    "    #creation of mask \n",
    "    self.gene=torch.bernoulli(torch.empty(1,maskLength).uniform_(0,1))\n",
    "    self.fit=0\n",
    "\n",
    "    \n",
    "\n",
    "    #the above line  specifies the mask length\n",
    "  \n",
    "\n",
    "\n",
    "  def fitness(self,model):\n",
    "    # finding the fitness of a particular mask\n",
    "    #accuracy of all training set is the fitness in one epoch \n",
    "    model.train()#putting model in train mode \n",
    "    #running_loss=0\n",
    "\n",
    "    running_corrects=0\n",
    "    for inputs,labels in dataloader ['train']:\n",
    "      inputs=inputs.to(device)\n",
    "      labels=labels.to(device )\n",
    "      outputs=model.Forward(inputs,self.gene )\n",
    "      _,preds=torch.max(outputs,1)\n",
    "      #loss=criterion (outputs,labels)\n",
    "      running_corrects+=torch.sum(preds==labels.data)\n",
    "    epoch_acc=running_corrects.double()/dataset_sizes['train']\n",
    "    self.fit =epoch_acc\n",
    "    #print (epoch_acc.shape ,type (epoch_acc))\n",
    "    return epoch_acc\n",
    "    \n",
    "\n",
    "      \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #model,losses,self.fitness=train_model(model,criterion,optimizer,1,self.gene)\n",
    "    #finding the fitness of each mask /gene with a single model \n",
    "  def crossover (self,parent2):\n",
    "    child =DNA(self.maskLength)\n",
    "    midpoint =random .randint (0,self.maskLength-1)\n",
    "    for i in range (0,self.maskLength):\n",
    "      if (i>midpoint):\n",
    "        child.gene [0,i]=self.gene[0,i]\n",
    "      else :\n",
    "        child.gene [0,i]=parent2.gene[0,i]\n",
    "    #one parent is the passed in the argument \n",
    "    #another parent is the one from which this function is called \n",
    "    #another parent is self.gene\n",
    "    return child \n",
    "\n",
    "  def mutate(self,mutation_rate):\n",
    "    for i in range (self.maskLength):\n",
    "      if (random.randint (0,99)<=mutation_rate*100):\n",
    "        self.gene[0,i]=1#randomly activate some of the activations \n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j12AJbkw1Gxp"
   },
   "outputs": [],
   "source": [
    "mutation_rate =0.01\n",
    "max_population=40\n",
    "maskLength=60\n",
    "model=Model()#creating the object of the class\n",
    "model.to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FcGt3-UvJHqe",
    "outputId": "f5d244b2-3cbc-4894-c2ee-d0ef5d4bcfb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch generations: 0/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ana\\envs\\packt_torch\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest fitness in the generation: \n",
      "tensor(0.1750, dtype=torch.float64)\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 2.2989 Acc: 0.2352 \n",
      "val Loss: 2.2943 Acc: 0.2377 \n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 2.2751 Acc: 0.2154 \n",
      "val Loss: 2.2403 Acc: 0.2121 \n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 2.1989 Acc: 0.2511 \n",
      "val Loss: 2.1496 Acc: 0.2972 \n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 2.1066 Acc: 0.3896 \n",
      "val Loss: 2.0474 Acc: 0.5116 \n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.9977 Acc: 0.5406 \n",
      "val Loss: 1.9403 Acc: 0.5644 \n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.9020 Acc: 0.6172 \n",
      "val Loss: 1.8552 Acc: 0.6537 \n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.8370 Acc: 0.6695 \n",
      "val Loss: 1.8079 Acc: 0.7141 \n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.7990 Acc: 0.7178 \n",
      "val Loss: 1.7783 Acc: 0.7320 \n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.7762 Acc: 0.7272 \n",
      "val Loss: 1.7607 Acc: 0.7370 \n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.7622 Acc: 0.7317 \n",
      "val Loss: 1.7491 Acc: 0.7417 \n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.7527 Acc: 0.7348 \n",
      "val Loss: 1.7414 Acc: 0.7440 \n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.7458 Acc: 0.7379 \n",
      "val Loss: 1.7355 Acc: 0.7464 \n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.7405 Acc: 0.7397 \n",
      "val Loss: 1.7308 Acc: 0.7486 \n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.7362 Acc: 0.7420 \n",
      "val Loss: 1.7269 Acc: 0.7505 \n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.7326 Acc: 0.7433 \n",
      "val Loss: 1.7237 Acc: 0.7521 \n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.7225 Acc: 0.7548 \n",
      "val Loss: 1.6869 Acc: 0.8106 \n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.6873 Acc: 0.8076 \n",
      "val Loss: 1.6752 Acc: 0.8178 \n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.6775 Acc: 0.8126 \n",
      "val Loss: 1.6667 Acc: 0.8229 \n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.6704 Acc: 0.8169 \n",
      "val Loss: 1.6604 Acc: 0.8260 \n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.6647 Acc: 0.8195 \n",
      "val Loss: 1.6554 Acc: 0.8283 \n",
      "Training complete in 5m 58s\n",
      "Best val Acc: 0.828300\n",
      "Epoch generations: 1/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.5924, dtype=torch.float64)\n",
      "Epoch generations: 2/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.5727, dtype=torch.float64)\n",
      "Epoch generations: 3/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.5727, dtype=torch.float64)\n",
      "Epoch generations: 4/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.6325, dtype=torch.float64)\n",
      "Epoch generations: 5/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.6515, dtype=torch.float64)\n",
      "Epoch generations: 6/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.6325, dtype=torch.float64)\n",
      "Epoch generations: 7/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.6425, dtype=torch.float64)\n",
      "Epoch generations: 8/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.6746, dtype=torch.float64)\n",
      "Epoch generations: 9/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.6501, dtype=torch.float64)\n",
      "Epoch generations: 10/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7198, dtype=torch.float64)\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.6892 Acc: 0.8117 \n",
      "val Loss: 1.6739 Acc: 0.8242 \n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.6753 Acc: 0.8201 \n",
      "val Loss: 1.6638 Acc: 0.8300 \n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.6671 Acc: 0.8234 \n",
      "val Loss: 1.6569 Acc: 0.8323 \n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.6610 Acc: 0.8263 \n",
      "val Loss: 1.6514 Acc: 0.8348 \n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.6562 Acc: 0.8281 \n",
      "val Loss: 1.6475 Acc: 0.8371 \n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.6524 Acc: 0.8298 \n",
      "val Loss: 1.6439 Acc: 0.8378 \n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.6491 Acc: 0.8309 \n",
      "val Loss: 1.6408 Acc: 0.8380 \n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.6450 Acc: 0.8326 \n",
      "val Loss: 1.6326 Acc: 0.8467 \n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.6264 Acc: 0.8676 \n",
      "val Loss: 1.6123 Acc: 0.8806 \n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.6118 Acc: 0.8807 \n",
      "val Loss: 1.6019 Acc: 0.8888 \n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.6033 Acc: 0.8863 \n",
      "val Loss: 1.5942 Acc: 0.8910 \n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.5972 Acc: 0.8899 \n",
      "val Loss: 1.5887 Acc: 0.8943 \n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.5925 Acc: 0.8925 \n",
      "val Loss: 1.5846 Acc: 0.8969 \n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.5888 Acc: 0.8952 \n",
      "val Loss: 1.5813 Acc: 0.8986 \n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.5857 Acc: 0.8967 \n",
      "val Loss: 1.5782 Acc: 0.9014 \n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.5831 Acc: 0.8980 \n",
      "val Loss: 1.5761 Acc: 0.9020 \n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.5809 Acc: 0.8985 \n",
      "val Loss: 1.5740 Acc: 0.9032 \n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.5790 Acc: 0.8996 \n",
      "val Loss: 1.5723 Acc: 0.9037 \n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.5773 Acc: 0.9005 \n",
      "val Loss: 1.5704 Acc: 0.9061 \n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.5758 Acc: 0.9016 \n",
      "val Loss: 1.5695 Acc: 0.9058 \n",
      "Training complete in 5m 50s\n",
      "Best val Acc: 0.906100\n",
      "Epoch generations: 11/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9016, dtype=torch.float64)\n",
      "Epoch generations: 12/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7246, dtype=torch.float64)\n",
      "Epoch generations: 13/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7174, dtype=torch.float64)\n",
      "Epoch generations: 14/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7185, dtype=torch.float64)\n",
      "Epoch generations: 15/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7206, dtype=torch.float64)\n",
      "Epoch generations: 16/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9016, dtype=torch.float64)\n",
      "Epoch generations: 17/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7246, dtype=torch.float64)\n",
      "Epoch generations: 18/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.8771, dtype=torch.float64)\n",
      "Epoch generations: 19/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.6648, dtype=torch.float64)\n",
      "Epoch generations: 20/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.8771, dtype=torch.float64)\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.5763 Acc: 0.9005 \n",
      "val Loss: 1.5690 Acc: 0.9044 \n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.5741 Acc: 0.9021 \n",
      "val Loss: 1.5679 Acc: 0.9059 \n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.5728 Acc: 0.9026 \n",
      "val Loss: 1.5666 Acc: 0.9063 \n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.5717 Acc: 0.9031 \n",
      "val Loss: 1.5656 Acc: 0.9081 \n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.5706 Acc: 0.9046 \n",
      "val Loss: 1.5645 Acc: 0.9086 \n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.5697 Acc: 0.9049 \n",
      "val Loss: 1.5637 Acc: 0.9087 \n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.5688 Acc: 0.9054 \n",
      "val Loss: 1.5624 Acc: 0.9109 \n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.5680 Acc: 0.9056 \n",
      "val Loss: 1.5619 Acc: 0.9099 \n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.5672 Acc: 0.9065 \n",
      "val Loss: 1.5611 Acc: 0.9104 \n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.5665 Acc: 0.9068 \n",
      "val Loss: 1.5602 Acc: 0.9112 \n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.5658 Acc: 0.9071 \n",
      "val Loss: 1.5595 Acc: 0.9110 \n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.5652 Acc: 0.9076 \n",
      "val Loss: 1.5590 Acc: 0.9118 \n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.5645 Acc: 0.9082 \n",
      "val Loss: 1.5586 Acc: 0.9123 \n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.5639 Acc: 0.9084 \n",
      "val Loss: 1.5581 Acc: 0.9116 \n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.5633 Acc: 0.9089 \n",
      "val Loss: 1.5576 Acc: 0.9134 \n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.5628 Acc: 0.9089 \n",
      "val Loss: 1.5566 Acc: 0.9130 \n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.5623 Acc: 0.9095 \n",
      "val Loss: 1.5562 Acc: 0.9137 \n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.5618 Acc: 0.9099 \n",
      "val Loss: 1.5558 Acc: 0.9134 \n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.5613 Acc: 0.9105 \n",
      "val Loss: 1.5556 Acc: 0.9137 \n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.5609 Acc: 0.9103 \n",
      "val Loss: 1.5549 Acc: 0.9144 \n",
      "Training complete in 5m 57s\n",
      "Best val Acc: 0.914400\n",
      "Epoch generations: 21/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7080, dtype=torch.float64)\n",
      "Epoch generations: 22/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9076, dtype=torch.float64)\n",
      "Epoch generations: 23/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9107, dtype=torch.float64)\n",
      "Epoch generations: 24/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7006, dtype=torch.float64)\n",
      "Epoch generations: 25/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.6966, dtype=torch.float64)\n",
      "Epoch generations: 26/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7081, dtype=torch.float64)\n",
      "Epoch generations: 27/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9107, dtype=torch.float64)\n",
      "Epoch generations: 28/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7081, dtype=torch.float64)\n",
      "Epoch generations: 29/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7081, dtype=torch.float64)\n",
      "Epoch generations: 30/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.7146, dtype=torch.float64)\n",
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.6174 Acc: 0.8525 \n",
      "val Loss: 1.5674 Acc: 0.9052 \n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.5712 Acc: 0.9022 \n",
      "val Loss: 1.5620 Acc: 0.9100 \n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.5673 Acc: 0.9062 \n",
      "val Loss: 1.5599 Acc: 0.9132 \n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.5652 Acc: 0.9076 \n",
      "val Loss: 1.5583 Acc: 0.9132 \n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.5638 Acc: 0.9084 \n",
      "val Loss: 1.5575 Acc: 0.9137 \n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.5628 Acc: 0.9092 \n",
      "val Loss: 1.5563 Acc: 0.9150 \n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.5618 Acc: 0.9103 \n",
      "val Loss: 1.5554 Acc: 0.9153 \n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.5609 Acc: 0.9106 \n",
      "val Loss: 1.5548 Acc: 0.9150 \n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.5601 Acc: 0.9116 \n",
      "val Loss: 1.5544 Acc: 0.9148 \n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.5594 Acc: 0.9120 \n",
      "val Loss: 1.5537 Acc: 0.9164 \n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.5588 Acc: 0.9129 \n",
      "val Loss: 1.5532 Acc: 0.9165 \n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.5583 Acc: 0.9131 \n",
      "val Loss: 1.5525 Acc: 0.9173 \n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.5577 Acc: 0.9136 \n",
      "val Loss: 1.5521 Acc: 0.9174 \n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.5571 Acc: 0.9136 \n",
      "val Loss: 1.5516 Acc: 0.9176 \n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.5567 Acc: 0.9139 \n",
      "val Loss: 1.5512 Acc: 0.9178 \n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.5562 Acc: 0.9143 \n",
      "val Loss: 1.5507 Acc: 0.9191 \n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.5558 Acc: 0.9147 \n",
      "val Loss: 1.5504 Acc: 0.9192 \n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.5554 Acc: 0.9153 \n",
      "val Loss: 1.5498 Acc: 0.9200 \n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.5549 Acc: 0.9155 \n",
      "val Loss: 1.5495 Acc: 0.9198 \n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.5545 Acc: 0.9157 \n",
      "val Loss: 1.5493 Acc: 0.9194 \n",
      "Training complete in 5m 55s\n",
      "Best val Acc: 0.920000\n",
      "Epoch generations: 31/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9039, dtype=torch.float64)\n",
      "Epoch generations: 32/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9093, dtype=torch.float64)\n",
      "Epoch generations: 33/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.8909, dtype=torch.float64)\n",
      "Epoch generations: 34/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9093, dtype=torch.float64)\n",
      "Epoch generations: 35/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9093, dtype=torch.float64)\n",
      "Epoch generations: 36/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9093, dtype=torch.float64)\n",
      "Epoch generations: 37/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.8895, dtype=torch.float64)\n",
      "Epoch generations: 38/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9093, dtype=torch.float64)\n",
      "Epoch generations: 39/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9093, dtype=torch.float64)\n",
      "Epoch generations: 40/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.8895, dtype=torch.float64)\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.5579 Acc: 0.9118 \n",
      "val Loss: 1.5514 Acc: 0.9171 \n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.5559 Acc: 0.9138 \n",
      "val Loss: 1.5505 Acc: 0.9179 \n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.5552 Acc: 0.9144 \n",
      "val Loss: 1.5499 Acc: 0.9187 \n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.5545 Acc: 0.9153 \n",
      "val Loss: 1.5495 Acc: 0.9193 \n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.5541 Acc: 0.9160 \n",
      "val Loss: 1.5488 Acc: 0.9196 \n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.5536 Acc: 0.9160 \n",
      "val Loss: 1.5484 Acc: 0.9205 \n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.5532 Acc: 0.9164 \n",
      "val Loss: 1.5481 Acc: 0.9203 \n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.5528 Acc: 0.9167 \n",
      "val Loss: 1.5476 Acc: 0.9208 \n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.5524 Acc: 0.9168 \n",
      "val Loss: 1.5474 Acc: 0.9213 \n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.5521 Acc: 0.9175 \n",
      "val Loss: 1.5474 Acc: 0.9212 \n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.5517 Acc: 0.9177 \n",
      "val Loss: 1.5467 Acc: 0.9223 \n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.5514 Acc: 0.9174 \n",
      "val Loss: 1.5464 Acc: 0.9224 \n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.5510 Acc: 0.9182 \n",
      "val Loss: 1.5461 Acc: 0.9224 \n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.5507 Acc: 0.9184 \n",
      "val Loss: 1.5460 Acc: 0.9225 \n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.5504 Acc: 0.9187 \n",
      "val Loss: 1.5454 Acc: 0.9236 \n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.5501 Acc: 0.9192 \n",
      "val Loss: 1.5455 Acc: 0.9230 \n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.5498 Acc: 0.9192 \n",
      "val Loss: 1.5451 Acc: 0.9235 \n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.5495 Acc: 0.9195 \n",
      "val Loss: 1.5448 Acc: 0.9227 \n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.5491 Acc: 0.9200 \n",
      "val Loss: 1.5444 Acc: 0.9239 \n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.5488 Acc: 0.9199 \n",
      "val Loss: 1.5442 Acc: 0.9241 \n",
      "Training complete in 6m 3s\n",
      "Best val Acc: 0.924100\n",
      "Epoch generations: 41/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9211, dtype=torch.float64)\n",
      "Epoch generations: 42/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9211, dtype=torch.float64)\n",
      "Epoch generations: 43/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9211, dtype=torch.float64)\n",
      "Epoch generations: 44/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9210, dtype=torch.float64)\n",
      "Epoch generations: 45/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9211, dtype=torch.float64)\n",
      "Epoch generations: 46/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9210, dtype=torch.float64)\n",
      "Epoch generations: 47/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9210, dtype=torch.float64)\n",
      "Epoch generations: 48/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.9187, dtype=torch.float64)\n",
      "Epoch generations: 49/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.8049, dtype=torch.float64)\n",
      "Epoch generations: 50/500\n",
      "highest fitness in the generation: \n",
      "tensor(0.8046, dtype=torch.float64)\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.5562 Acc: 0.9101 \n",
      "val Loss: 1.5462 Acc: 0.9195 \n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.5499 Acc: 0.9169 \n",
      "val Loss: 1.5447 Acc: 0.9215 \n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.5489 Acc: 0.9177 \n",
      "val Loss: 1.5439 Acc: 0.9232 \n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.5482 Acc: 0.9182 \n",
      "val Loss: 1.5436 Acc: 0.9233 \n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.5478 Acc: 0.9192 \n",
      "val Loss: 1.5429 Acc: 0.9227 \n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.5473 Acc: 0.9194 \n",
      "val Loss: 1.5426 Acc: 0.9239 \n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.5470 Acc: 0.9199 \n",
      "val Loss: 1.5423 Acc: 0.9239 \n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.5466 Acc: 0.9204 \n",
      "val Loss: 1.5421 Acc: 0.9243 \n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.5463 Acc: 0.9204 \n",
      "val Loss: 1.5416 Acc: 0.9253 \n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.5460 Acc: 0.9208 \n",
      "val Loss: 1.5417 Acc: 0.9244 \n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.5457 Acc: 0.9210 \n",
      "val Loss: 1.5414 Acc: 0.9256 \n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.5454 Acc: 0.9214 \n",
      "val Loss: 1.5410 Acc: 0.9254 \n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.5451 Acc: 0.9218 \n",
      "val Loss: 1.5408 Acc: 0.9261 \n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.5449 Acc: 0.9221 \n",
      "val Loss: 1.5405 Acc: 0.9265 \n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.5446 Acc: 0.9220 \n",
      "val Loss: 1.5404 Acc: 0.9262 \n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.5444 Acc: 0.9225 \n",
      "val Loss: 1.5399 Acc: 0.9273 \n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.5441 Acc: 0.9231 \n",
      "val Loss: 1.5399 Acc: 0.9273 \n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.5438 Acc: 0.9231 \n",
      "val Loss: 1.5396 Acc: 0.9267 \n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.5437 Acc: 0.9233 \n",
      "val Loss: 1.5393 Acc: 0.9274 \n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.5434 Acc: 0.9234 \n",
      "val Loss: 1.5393 Acc: 0.9274 \n",
      "Training complete in 6m 4s\n",
      "Best val Acc: 0.927400\n",
      "Epoch generations: 51/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-993709557031>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch generations: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochgens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/500\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m   \u001b[0mpopulation\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcalcFitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m   \u001b[1;31m#model is passed into the calcuation fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[0mpopulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaturalSelection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-e66a1ff6b6f0>\u001b[0m in \u001b[0;36mcalcFitness\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     27\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m# going through all the entities of population\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m#dna=DNA(self.maskLength)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m#print (\"entity\"+str(i)+\"/\"+str(self.popmax))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-464e1af17161>\u001b[0m in \u001b[0;36mfitness\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mrunning_corrects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m       \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ana\\envs\\packt_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ana\\envs\\packt_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ana\\envs\\packt_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ana\\envs\\packt_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ana\\envs\\packt_torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ana\\envs\\packt_torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ana\\envs\\packt_torch\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mnchannel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#control block controls the epochs and the generations of mask\n",
    "epochgens=0\n",
    "population =Population(mutation_rate,max_population,maskLength)\n",
    "# an object of the population class \n",
    "while (epochgens<500):\n",
    "    \n",
    "    \n",
    "  print (\"Epoch generations: \"+str(epochgens)+\"/500\")\n",
    "  population .calcFitness(model)\n",
    "  #model is passed into the calcuation fitness \n",
    "  population.naturalSelection()\n",
    "\n",
    "\n",
    "  fittestmask=population .fittest()\n",
    "  #accuarcy of fittest mask\n",
    "\n",
    "  #print (fittestmask .gene)\n",
    "  acc=fittestmask.fitness(model)\n",
    "  print (\"highest fitness in the generation: \")\n",
    "  print (acc)\n",
    "  #the above function find the fittest mask of the entire current population\n",
    "  # generates the population \n",
    "\n",
    "  if (epochgens%10==0):#every 10 generations \n",
    "    model,losses,accuracies=train_model(model,criterion,optimizer,fittestmask.gene,20)#train model for 5 epochs \n",
    "    # and the pass the fittest mask as one of the parameters \n",
    "  population.generate()\n",
    "  epochgens+=1\n",
    "#break aftr 500 generattions and epochs and generative algo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ga_dropout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
