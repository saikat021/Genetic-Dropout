{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import time \n",
    "from torchvision import datasets ,transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn \n",
    "from torch.nn.functional import relu ,softmax \n",
    "import copy \n",
    "from torch.utils.data import Subset\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform=transforms.Compose ([transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "60\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class light_source_dataset(Dataset):\n",
    "    def __init__(self,path,transform):\n",
    "        self.df_data=pd.read_csv(path)\n",
    "        self.df_data['Classifier'] = pd.Categorical(pd.factorize(self.df_data['Classifier'])[0])\n",
    "        self.labels=np.asarray(self.df_data.iloc[:,self.df_data.shape[1]-1])\n",
    "        self.image_as_np=np.asarray(self.df_data.iloc[:,0:self.df_data.shape[1]-1]).astype('uint8')\n",
    "        self.trans=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df_data.index)\n",
    "    def __getitem__(self,index):\n",
    "        image_np=self.image_as_np[index,:,None]\n",
    "       \n",
    "        pillow_image=Image.fromarray(image_np.astype('uint8'))\n",
    "        \n",
    "        single_label=self.labels[index]\n",
    "        if (self.trans is not None):\n",
    "            img_as_tensor=self.trans(pillow_image)\n",
    "        \n",
    "        \n",
    "            \n",
    "        return (img_as_tensor,single_label)\n",
    "        \n",
    "dataset=light_source_dataset('Zoo/Zoo.csv',data_transform)\n",
    "print(len(dataset))\n",
    "train_size=int (len(dataset)*0.6)\n",
    "test_size=len(dataset)-train_size\n",
    "trainloader=DataLoader(dataset,batch_size=1)\n",
    "torch.manual_seed(1)\n",
    "train_data,test_data=torch.utils.data.random_split(dataset,[int (train_size), int (test_size)])\n",
    "dataloader={'train':DataLoader(train_data,shuffle=False ,batch_size=16),\n",
    "            'val':DataLoader(test_data,shuffle=False,batch_size=16\n",
    "                            )}\n",
    "\n",
    "dataset_sizes={'train':len(train_data),\n",
    "               'val':len(test_data)}\n",
    "\n",
    "device=torch.device(\"cuda:0\"if torch.cuda.is_available () else \"cpu\")\n",
    "print(dataset_sizes[\"train\"])\n",
    "print (dataset_sizes[\"val\"])\n",
    "#for images,labels in dataloader['train']:\n",
    " #   print(labels)\n",
    "\n",
    " \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super (Model,self ).__init__()\n",
    "        self .linear1=nn.Linear (16,100)\n",
    "        self.linear2=nn.Linear (100,7)\n",
    "        \n",
    "    def Forward (self,x,mask,p):\n",
    "        #feed forward function \n",
    "        x=x.view(-1,16)\n",
    "        act1=relu(self.linear1(x))\n",
    "        act1_masked =self.masking (act1,mask,p)\n",
    "        act2=softmax(self.linear2(act1_masked ))\n",
    "        return act2\n",
    "    \n",
    "    \n",
    "    \n",
    "    def masking (self,act1,mask,p):\n",
    "        if (self.training ==True ):\n",
    "            return ((act1*mask)/p)\n",
    "        else :\n",
    "            return (act1)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer,mask,p, num_epochs=25):\n",
    "  # the mask has to be specified \n",
    "\n",
    "      \n",
    "      since = time.time()\n",
    "\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "      best_acc = 0.0\n",
    "      losses=[]\n",
    "      accuracies=[]\n",
    "\n",
    "      for epoch in range(num_epochs):\n",
    "          print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "          print('-' * 10)\n",
    "\n",
    "          # Each epoch has a training and validation phase\n",
    "          for phase in ['train', 'val']:\n",
    "              if phase == 'train':\n",
    "                  \n",
    "                  model.train()  # Set model to training mode\n",
    "              else:\n",
    "\n",
    "                  model.eval()   # Set model to evaluate mode\n",
    "\n",
    "              running_loss = 0.0\n",
    "              running_corrects = 0\n",
    "\n",
    "              # Iterate over data.\n",
    "              for inputs, labels in dataloader[phase]:\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs= model.Forward(inputs,mask,p)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)# backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        #print (model.linear1.weight.grad)\n",
    "                        #print (model.linear2.weight.grad)\n",
    "\n",
    "                  # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                  \n",
    "\n",
    "              epoch_loss = running_loss / dataset_sizes[phase]\n",
    "              epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "\n",
    "              print('{} Loss: {:.4f} Acc: {:.4f} '.format(\n",
    "                  phase, epoch_loss, epoch_acc))\n",
    "\n",
    "              # deep copy the model\n",
    "              if phase == 'val' and epoch_acc > best_acc:\n",
    "                  best_acc = epoch_acc\n",
    "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "              if phase=='train':\n",
    "                losses.append(epoch_loss)\n",
    "                accuracies.append(epoch_acc)\n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "      time_elapsed = time.time() - since\n",
    "      print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "          time_elapsed // 60, time_elapsed % 60))\n",
    "      print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "      # load best model weights\n",
    "      model.load_state_dict(best_model_wts)\n",
    "      return model,losses,accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Population:\n",
    "    \n",
    "    def __init__(self,m,num,maskLength):\n",
    "        # constructor for initialising the population list\n",
    "        #list of DNA objects\n",
    "        self.population=[]\n",
    "        #muation rate for mutation\n",
    "        self.mutation_rate=m\n",
    "        #maximum number of entities in the population\n",
    "        self.popmax=num\n",
    "\n",
    "        self.maskLength=maskLength\n",
    "        for i in range (num):\n",
    "            #creating a dna object\n",
    "            #an initial random population created \n",
    "            dna =DNA(self.maskLength)\n",
    "            self.population.append (dna)\n",
    "      \n",
    "        self.matingPool=[]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calcFitness (self,model):\n",
    "        # going through all the entities of population \n",
    "        #finding fitness of all population entities \n",
    "        for i in range(0,self.popmax):\n",
    "            self.population[i].fitness (model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def naturalSelection(self):\n",
    "        self.matingPool=[]\n",
    "        maxFitness=0\n",
    "        for i in range (self.popmax):\n",
    "            # moving throught the entire population \n",
    "            if (self.population[i].fit>maxFitness):\n",
    "                maxFitness=self.population[i].fit\n",
    "       \n",
    "        # max Fitness has the maximum loss score of the entire population  \n",
    "        for i in range (self.popmax ):\n",
    "        # iterating through the all inviduals of the population\n",
    "            n=self.Mymap(self.population[i].fit,0,maxFitness,0,1)\n",
    "        \n",
    "            n=math.floor(n*100)\n",
    "            \n",
    "            for j in range (n):\n",
    "                #creating mating pool\n",
    "                self.matingPool.append (self.population[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def Mymap(self,num,prevlow,prevhigh,nextlow,nexthigh):\n",
    "        \n",
    "        prevrange =float((num-prevlow)/(prevhigh-prevlow))\n",
    "        return nextlow+(nexthigh-nextlow)*prevrange\n",
    "\n",
    "\n",
    "\n",
    "    def   generate (self):\n",
    "        for i in range (self.popmax ):\n",
    "            index_1=math.floor(random.randint  (0,len(self.matingPool)-1))\n",
    "            index_2=math.floor (random.randint (0,len(self.matingPool)-1))\n",
    "            parent1=self.matingPool[index_1]\n",
    "            parent2=self.matingPool[index_2]\n",
    "            child=parent1.crossover(parent2)\n",
    "            child.mutate(self.mutation_rate)\n",
    "            self.population[i]=child \n",
    "\n",
    "\n",
    "    def fittest(self):\n",
    "        #returns the fiitest individual mask of the population \n",
    "        #also returns the keeping probability of the fittest mask \n",
    "        fittest=self.population[0]\n",
    "        for i  in range (self.popmax):\n",
    "            if (fittest.fit<self.population[i].fit):\n",
    "                fittest=self.population[i]\n",
    "        return fittest,fittest.keep_prob()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class DNA:\n",
    "    \n",
    "    \n",
    "    def __init__(self,maskLength):\n",
    "        #constructor for the creation of the mask as a gene object \n",
    "        self.maskLength=maskLength\n",
    "        #creation of mask \n",
    "        self.gene=torch.bernoulli(torch.empty(1,maskLength).uniform_(0,1))\n",
    "        self.fit=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def keep_prob (self):\n",
    "\n",
    "        num_one =0\n",
    "        for i in range (self.maskLength):\n",
    "            if (self.gene[0,i]==1):\n",
    "                num_one=num_one+1\n",
    "        return float(num_one/self.maskLength)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fitness(self,model):\n",
    "        # finding the fitness of a particular mask\n",
    "        #accuracy of all training set is the fitness in one epoch\n",
    "        #putting model in train mode \n",
    "        running_loss=0\n",
    "        running_corrects=0\n",
    "        model.train()\n",
    "        \n",
    "        for inputs,labels in dataloader ['train']:\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device )\n",
    "            outputs=model.Forward(inputs,self.gene,self.keep_prob())\n",
    "            _,preds=torch.max(outputs,1)\n",
    "            loss=criterion (outputs,labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / dataset_sizes['train']\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
    "        \n",
    "        self.fit=epoch_acc\n",
    "        return epoch_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def crossover (self,parent2):\n",
    "        #one parent is the passed in the argument \n",
    "        #another parent is the one from which this function is called \n",
    "        #another parent is self.gene\n",
    "        child =DNA(self.maskLength)\n",
    "        midpoint =random .randint (0,self.maskLength-1)\n",
    "        for i in range (0,self.maskLength):\n",
    "            if (i>midpoint):\n",
    "                child.gene [0,i]=self.gene[0,i]\n",
    "            else :\n",
    "                child.gene [0,i]=parent2.gene[0,i]\n",
    "        \n",
    "        return child \n",
    "\n",
    "    def mutate(self,mutation_rate):\n",
    "        #randomly activate some of the nodes  \n",
    "        #mutate some of the genes \n",
    "        for i in range (self.maskLength):\n",
    "            if (random.randint (0,99)<=mutation_rate*100):\n",
    "                self.gene[0,i]=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_rate =0.20\n",
    "max_population=30\n",
    "maskLength=100\n",
    "#seeded so that each time same initial weights generated \n",
    "torch.manual_seed(6)\n",
    "model=Model()#creating the object of the class\n",
    "model.to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch generations ( 0 /200) :"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ana\\envs\\packt_torch\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(fittest mask) tensor(0.2000, dtype=torch.float64) keep_prob 0.49\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9458 Acc: 0.2000 \n",
      "val Loss: 1.9476 Acc: 0.0732 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9457 Acc: 0.2000 \n",
      "val Loss: 1.9476 Acc: 0.0732 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9455 Acc: 0.2000 \n",
      "val Loss: 1.9475 Acc: 0.0732 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9453 Acc: 0.2000 \n",
      "val Loss: 1.9474 Acc: 0.0732 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9450 Acc: 0.2000 \n",
      "val Loss: 1.9473 Acc: 0.0732 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9447 Acc: 0.2000 \n",
      "val Loss: 1.9471 Acc: 0.0976 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9444 Acc: 0.2000 \n",
      "val Loss: 1.9470 Acc: 0.1951 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9440 Acc: 0.2000 \n",
      "val Loss: 1.9469 Acc: 0.1951 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9437 Acc: 0.2000 \n",
      "val Loss: 1.9467 Acc: 0.1951 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9434 Acc: 0.2000 \n",
      "val Loss: 1.9466 Acc: 0.1951 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9430 Acc: 0.2000 \n",
      "val Loss: 1.9465 Acc: 0.1951 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9427 Acc: 0.2000 \n",
      "val Loss: 1.9463 Acc: 0.1951 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9423 Acc: 0.2000 \n",
      "val Loss: 1.9462 Acc: 0.1951 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9420 Acc: 0.2000 \n",
      "val Loss: 1.9461 Acc: 0.1951 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9416 Acc: 0.2000 \n",
      "val Loss: 1.9459 Acc: 0.1951 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9412 Acc: 0.2000 \n",
      "val Loss: 1.9458 Acc: 0.1951 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9409 Acc: 0.2000 \n",
      "val Loss: 1.9456 Acc: 0.1951 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9405 Acc: 0.2000 \n",
      "val Loss: 1.9455 Acc: 0.1951 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9401 Acc: 0.2000 \n",
      "val Loss: 1.9453 Acc: 0.1951 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.2000 \n",
      "val Loss: 1.9452 Acc: 0.1951 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9393 Acc: 0.2000 \n",
      "val Loss: 1.9451 Acc: 0.1951 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9390 Acc: 0.2000 \n",
      "val Loss: 1.9449 Acc: 0.1951 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9386 Acc: 0.2000 \n",
      "val Loss: 1.9448 Acc: 0.1951 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9382 Acc: 0.2000 \n",
      "val Loss: 1.9446 Acc: 0.1951 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9378 Acc: 0.2000 \n",
      "val Loss: 1.9445 Acc: 0.1951 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9374 Acc: 0.2000 \n",
      "val Loss: 1.9443 Acc: 0.1951 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9370 Acc: 0.2000 \n",
      "val Loss: 1.9442 Acc: 0.1951 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9366 Acc: 0.2000 \n",
      "val Loss: 1.9440 Acc: 0.1951 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9362 Acc: 0.2000 \n",
      "val Loss: 1.9438 Acc: 0.0488 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9358 Acc: 0.2000 \n",
      "val Loss: 1.9437 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 1 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.54\n",
      "Epoch generations ( 2 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.64\n",
      "Epoch generations ( 3 /200) :accuracy(fittest mask) tensor(0.4667, dtype=torch.float64) keep_prob 0.67\n",
      "Epoch generations ( 4 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.84\n",
      "Epoch generations ( 5 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.82\n",
      "Epoch generations ( 6 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.89\n",
      "Epoch generations ( 7 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.93\n",
      "Epoch generations ( 8 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.96\n",
      "Epoch generations ( 9 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.97\n",
      "Epoch generations ( 10 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.95\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9411 Acc: 0.4500 \n",
      "val Loss: 1.9435 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9408 Acc: 0.4500 \n",
      "val Loss: 1.9434 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9406 Acc: 0.4500 \n",
      "val Loss: 1.9432 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9403 Acc: 0.4500 \n",
      "val Loss: 1.9431 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9401 Acc: 0.4500 \n",
      "val Loss: 1.9429 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9398 Acc: 0.4500 \n",
      "val Loss: 1.9428 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9396 Acc: 0.4500 \n",
      "val Loss: 1.9426 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9393 Acc: 0.4500 \n",
      "val Loss: 1.9425 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9390 Acc: 0.4500 \n",
      "val Loss: 1.9423 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9388 Acc: 0.4500 \n",
      "val Loss: 1.9421 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9385 Acc: 0.4500 \n",
      "val Loss: 1.9420 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9383 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9380 Acc: 0.4500 \n",
      "val Loss: 1.9417 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9377 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9375 Acc: 0.4500 \n",
      "val Loss: 1.9414 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9372 Acc: 0.4500 \n",
      "val Loss: 1.9412 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9369 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9367 Acc: 0.4500 \n",
      "val Loss: 1.9409 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9364 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9361 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9358 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9356 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9353 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9350 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9347 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9345 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9342 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9339 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9336 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9333 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 11 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.95\n",
      "Epoch generations ( 12 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.96\n",
      "Epoch generations ( 13 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.99\n",
      "Epoch generations ( 14 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.96\n",
      "Epoch generations ( 15 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.98\n",
      "Epoch generations ( 16 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 17 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 18 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 19 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 20 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.99\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9419 Acc: 0.4500 \n",
      "val Loss: 1.9434 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9417 Acc: 0.4500 \n",
      "val Loss: 1.9432 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9414 Acc: 0.4500 \n",
      "val Loss: 1.9431 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9412 Acc: 0.4500 \n",
      "val Loss: 1.9429 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9409 Acc: 0.4500 \n",
      "val Loss: 1.9428 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9407 Acc: 0.4500 \n",
      "val Loss: 1.9426 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9404 Acc: 0.4500 \n",
      "val Loss: 1.9425 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9402 Acc: 0.4500 \n",
      "val Loss: 1.9423 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9399 Acc: 0.4500 \n",
      "val Loss: 1.9421 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.4500 \n",
      "val Loss: 1.9420 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9394 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9392 Acc: 0.4500 \n",
      "val Loss: 1.9417 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.9387 Acc: 0.4500 \n",
      "val Loss: 1.9414 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9384 Acc: 0.4500 \n",
      "val Loss: 1.9412 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9382 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9379 Acc: 0.4500 \n",
      "val Loss: 1.9409 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9377 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9374 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9371 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9369 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9366 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9363 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9361 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9358 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9355 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9353 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9350 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9347 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9345 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 21 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 22 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.99\n",
      "Epoch generations ( 23 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 24 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 25 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 26 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.99\n",
      "Epoch generations ( 27 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 28 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 29 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 30 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9417 Acc: 0.4500 \n",
      "val Loss: 1.9432 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9414 Acc: 0.4500 \n",
      "val Loss: 1.9431 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9412 Acc: 0.4500 \n",
      "val Loss: 1.9429 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9410 Acc: 0.4500 \n",
      "val Loss: 1.9428 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9407 Acc: 0.4500 \n",
      "val Loss: 1.9426 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9405 Acc: 0.4500 \n",
      "val Loss: 1.9424 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9402 Acc: 0.4500 \n",
      "val Loss: 1.9423 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9400 Acc: 0.4500 \n",
      "val Loss: 1.9421 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.4500 \n",
      "val Loss: 1.9420 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9395 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9392 Acc: 0.4500 \n",
      "val Loss: 1.9417 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9390 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9387 Acc: 0.4500 \n",
      "val Loss: 1.9414 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9385 Acc: 0.4500 \n",
      "val Loss: 1.9412 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9382 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9380 Acc: 0.4500 \n",
      "val Loss: 1.9409 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9377 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9374 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9372 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9369 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9367 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9364 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9361 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9359 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9356 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9353 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9351 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9348 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9345 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9343 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 31 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 32 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 33 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 34 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 0.99\n",
      "Epoch generations ( 35 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 36 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 37 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 38 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 39 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 40 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9414 Acc: 0.4500 \n",
      "val Loss: 1.9431 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9412 Acc: 0.4500 \n",
      "val Loss: 1.9429 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9409 Acc: 0.4500 \n",
      "val Loss: 1.9428 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9407 Acc: 0.4500 \n",
      "val Loss: 1.9426 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9405 Acc: 0.4500 \n",
      "val Loss: 1.9424 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9402 Acc: 0.4500 \n",
      "val Loss: 1.9423 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9400 Acc: 0.4500 \n",
      "val Loss: 1.9421 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.4500 \n",
      "val Loss: 1.9420 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9395 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9392 Acc: 0.4500 \n",
      "val Loss: 1.9417 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9390 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9387 Acc: 0.4500 \n",
      "val Loss: 1.9414 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9385 Acc: 0.4500 \n",
      "val Loss: 1.9412 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9382 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9379 Acc: 0.4500 \n",
      "val Loss: 1.9409 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9377 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9374 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9372 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9369 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9367 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9364 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9361 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9359 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9356 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9353 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9351 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9348 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9345 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9343 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.9340 Acc: 0.4500 \n",
      "val Loss: 1.9384 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 41 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 42 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 43 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 44 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 45 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 46 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 47 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 48 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 49 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 50 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9412 Acc: 0.4500 \n",
      "val Loss: 1.9429 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9409 Acc: 0.4500 \n",
      "val Loss: 1.9427 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9407 Acc: 0.4500 \n",
      "val Loss: 1.9426 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9404 Acc: 0.4500 \n",
      "val Loss: 1.9424 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9402 Acc: 0.4500 \n",
      "val Loss: 1.9423 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9399 Acc: 0.4500 \n",
      "val Loss: 1.9421 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.4500 \n",
      "val Loss: 1.9420 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9394 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9392 Acc: 0.4500 \n",
      "val Loss: 1.9417 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9387 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9384 Acc: 0.4500 \n",
      "val Loss: 1.9412 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9382 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9379 Acc: 0.4500 \n",
      "val Loss: 1.9409 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9377 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9374 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9372 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9369 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9366 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9364 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9361 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9359 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9356 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9353 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9351 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9348 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9345 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9342 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9340 Acc: 0.4500 \n",
      "val Loss: 1.9384 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9337 Acc: 0.4500 \n",
      "val Loss: 1.9382 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 51 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 52 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 53 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 54 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 55 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 56 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 57 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 58 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 59 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 60 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9409 Acc: 0.4500 \n",
      "val Loss: 1.9427 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9407 Acc: 0.4500 \n",
      "val Loss: 1.9426 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9404 Acc: 0.4500 \n",
      "val Loss: 1.9424 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9402 Acc: 0.4500 \n",
      "val Loss: 1.9423 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9399 Acc: 0.4500 \n",
      "val Loss: 1.9421 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.4500 \n",
      "val Loss: 1.9420 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9394 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9392 Acc: 0.4500 \n",
      "val Loss: 1.9417 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9387 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9384 Acc: 0.4500 \n",
      "val Loss: 1.9412 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9382 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9379 Acc: 0.4500 \n",
      "val Loss: 1.9409 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9377 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9374 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9371 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9369 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9366 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9364 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9361 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9358 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9356 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9353 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9350 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9348 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9345 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9342 Acc: 0.4500 \n",
      "val Loss: 1.9385 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9340 Acc: 0.4500 \n",
      "val Loss: 1.9384 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9337 Acc: 0.4500 \n",
      "val Loss: 1.9382 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9334 Acc: 0.4500 \n",
      "val Loss: 1.9380 Acc: 0.3415 \n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 61 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 62 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 63 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 64 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 65 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 66 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 67 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 68 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch generations ( 69 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 70 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9407 Acc: 0.4500 \n",
      "val Loss: 1.9426 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9404 Acc: 0.4500 \n",
      "val Loss: 1.9424 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9402 Acc: 0.4500 \n",
      "val Loss: 1.9423 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9399 Acc: 0.4500 \n",
      "val Loss: 1.9421 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.4500 \n",
      "val Loss: 1.9420 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9394 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9392 Acc: 0.4500 \n",
      "val Loss: 1.9416 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9387 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9384 Acc: 0.4500 \n",
      "val Loss: 1.9412 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9382 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9379 Acc: 0.4500 \n",
      "val Loss: 1.9409 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9377 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9374 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9371 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9369 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9366 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9364 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9361 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9358 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9356 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9353 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9350 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9348 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9345 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9342 Acc: 0.4500 \n",
      "val Loss: 1.9385 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9339 Acc: 0.4500 \n",
      "val Loss: 1.9384 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9337 Acc: 0.4500 \n",
      "val Loss: 1.9382 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9334 Acc: 0.4500 \n",
      "val Loss: 1.9380 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9331 Acc: 0.4500 \n",
      "val Loss: 1.9378 Acc: 0.3415 \n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 71 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 72 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 73 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 74 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 75 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 76 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 77 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 78 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 79 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 80 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9404 Acc: 0.4500 \n",
      "val Loss: 1.9424 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9402 Acc: 0.4500 \n",
      "val Loss: 1.9423 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9399 Acc: 0.4500 \n",
      "val Loss: 1.9421 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.4500 \n",
      "val Loss: 1.9420 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9394 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9392 Acc: 0.4500 \n",
      "val Loss: 1.9416 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9387 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9384 Acc: 0.4500 \n",
      "val Loss: 1.9412 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9382 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9379 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9376 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9374 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9371 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9369 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9366 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9363 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9361 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9358 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9355 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9353 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9350 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9347 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9345 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9342 Acc: 0.4500 \n",
      "val Loss: 1.9385 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9339 Acc: 0.4500 \n",
      "val Loss: 1.9384 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9336 Acc: 0.4500 \n",
      "val Loss: 1.9382 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9334 Acc: 0.4500 \n",
      "val Loss: 1.9380 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9331 Acc: 0.4500 \n",
      "val Loss: 1.9378 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9328 Acc: 0.4500 \n",
      "val Loss: 1.9377 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 81 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 82 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 83 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 84 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 85 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 86 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 87 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 88 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 89 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 90 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9402 Acc: 0.4500 \n",
      "val Loss: 1.9423 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9399 Acc: 0.4500 \n",
      "val Loss: 1.9421 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.4500 \n",
      "val Loss: 1.9419 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9394 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9392 Acc: 0.4500 \n",
      "val Loss: 1.9416 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9386 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9384 Acc: 0.4500 \n",
      "val Loss: 1.9412 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9381 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9379 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9376 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.9374 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9371 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9368 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9366 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9363 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9361 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9358 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9355 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9353 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9350 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9347 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9345 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9342 Acc: 0.4500 \n",
      "val Loss: 1.9385 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9339 Acc: 0.4500 \n",
      "val Loss: 1.9383 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9336 Acc: 0.4500 \n",
      "val Loss: 1.9382 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9334 Acc: 0.4500 \n",
      "val Loss: 1.9380 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9331 Acc: 0.4500 \n",
      "val Loss: 1.9378 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9328 Acc: 0.4500 \n",
      "val Loss: 1.9376 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9325 Acc: 0.4500 \n",
      "val Loss: 1.9375 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 91 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 92 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 93 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 94 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 95 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 96 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 97 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 98 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 99 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 100 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9399 Acc: 0.4500 \n",
      "val Loss: 1.9421 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.4500 \n",
      "val Loss: 1.9419 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9394 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9391 Acc: 0.4500 \n",
      "val Loss: 1.9416 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9386 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9384 Acc: 0.4500 \n",
      "val Loss: 1.9411 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9381 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9379 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9376 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9374 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9371 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9368 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9366 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9363 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9360 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9358 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9355 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9352 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9350 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9347 Acc: 0.4500 \n",
      "val Loss: 1.9388 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9344 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9342 Acc: 0.4500 \n",
      "val Loss: 1.9385 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9339 Acc: 0.4500 \n",
      "val Loss: 1.9383 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9336 Acc: 0.4500 \n",
      "val Loss: 1.9382 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9333 Acc: 0.4500 \n",
      "val Loss: 1.9380 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9331 Acc: 0.4500 \n",
      "val Loss: 1.9378 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9328 Acc: 0.4500 \n",
      "val Loss: 1.9376 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9325 Acc: 0.4500 \n",
      "val Loss: 1.9375 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9322 Acc: 0.4500 \n",
      "val Loss: 1.9373 Acc: 0.3415 \n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 101 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 102 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 103 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 104 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 105 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 106 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 107 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 108 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 109 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 110 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9397 Acc: 0.4500 \n",
      "val Loss: 1.9419 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9394 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9391 Acc: 0.4500 \n",
      "val Loss: 1.9416 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9386 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9384 Acc: 0.4500 \n",
      "val Loss: 1.9411 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9381 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9379 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9376 Acc: 0.4500 \n",
      "val Loss: 1.9407 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9373 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9371 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9368 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9366 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9363 Acc: 0.4500 \n",
      "val Loss: 1.9398 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9360 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9358 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9355 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9352 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9350 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9347 Acc: 0.4500 \n",
      "val Loss: 1.9388 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9344 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9342 Acc: 0.4500 \n",
      "val Loss: 1.9385 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9339 Acc: 0.4500 \n",
      "val Loss: 1.9383 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9336 Acc: 0.4500 \n",
      "val Loss: 1.9382 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9333 Acc: 0.4500 \n",
      "val Loss: 1.9380 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9330 Acc: 0.4500 \n",
      "val Loss: 1.9378 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9328 Acc: 0.4500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.9376 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9325 Acc: 0.4500 \n",
      "val Loss: 1.9375 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9322 Acc: 0.4500 \n",
      "val Loss: 1.9373 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9319 Acc: 0.4500 \n",
      "val Loss: 1.9371 Acc: 0.3415 \n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 111 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 112 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 113 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 114 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 115 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 116 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 117 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 118 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 119 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 120 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9394 Acc: 0.4500 \n",
      "val Loss: 1.9418 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9391 Acc: 0.4500 \n",
      "val Loss: 1.9416 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9415 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9386 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9384 Acc: 0.4500 \n",
      "val Loss: 1.9411 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9381 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9378 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9376 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9373 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9371 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9368 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9365 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9363 Acc: 0.4500 \n",
      "val Loss: 1.9398 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9360 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9358 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9355 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9352 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9350 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9347 Acc: 0.4500 \n",
      "val Loss: 1.9388 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9344 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9341 Acc: 0.4500 \n",
      "val Loss: 1.9385 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9339 Acc: 0.4500 \n",
      "val Loss: 1.9383 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9336 Acc: 0.4500 \n",
      "val Loss: 1.9381 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9333 Acc: 0.4500 \n",
      "val Loss: 1.9380 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9330 Acc: 0.4500 \n",
      "val Loss: 1.9378 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9328 Acc: 0.4500 \n",
      "val Loss: 1.9376 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9325 Acc: 0.4500 \n",
      "val Loss: 1.9374 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9322 Acc: 0.4500 \n",
      "val Loss: 1.9373 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9319 Acc: 0.4500 \n",
      "val Loss: 1.9371 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9316 Acc: 0.4500 \n",
      "val Loss: 1.9369 Acc: 0.3415 \n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 121 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 122 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 123 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 124 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 125 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 126 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 127 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 128 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 129 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 130 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9391 Acc: 0.4500 \n",
      "val Loss: 1.9416 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9414 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9386 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9384 Acc: 0.4500 \n",
      "val Loss: 1.9411 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9381 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9378 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9376 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9373 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9371 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9368 Acc: 0.4500 \n",
      "val Loss: 1.9402 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9365 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9363 Acc: 0.4500 \n",
      "val Loss: 1.9398 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9360 Acc: 0.4500 \n",
      "val Loss: 1.9397 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9357 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9355 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9352 Acc: 0.4500 \n",
      "val Loss: 1.9392 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9349 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9347 Acc: 0.4500 \n",
      "val Loss: 1.9388 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9344 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9341 Acc: 0.4500 \n",
      "val Loss: 1.9385 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9338 Acc: 0.4500 \n",
      "val Loss: 1.9383 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9336 Acc: 0.4500 \n",
      "val Loss: 1.9381 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9333 Acc: 0.4500 \n",
      "val Loss: 1.9380 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9330 Acc: 0.4500 \n",
      "val Loss: 1.9378 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9327 Acc: 0.4500 \n",
      "val Loss: 1.9376 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9325 Acc: 0.4500 \n",
      "val Loss: 1.9374 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9322 Acc: 0.4500 \n",
      "val Loss: 1.9373 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9319 Acc: 0.4500 \n",
      "val Loss: 1.9371 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9316 Acc: 0.4500 \n",
      "val Loss: 1.9369 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9313 Acc: 0.4500 \n",
      "val Loss: 1.9367 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 131 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 132 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 133 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 134 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 135 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 136 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch generations ( 137 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 138 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 139 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 140 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9389 Acc: 0.4500 \n",
      "val Loss: 1.9414 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9386 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9383 Acc: 0.4500 \n",
      "val Loss: 1.9411 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9381 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9378 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9376 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9373 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9370 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9368 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9365 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9363 Acc: 0.4500 \n",
      "val Loss: 1.9398 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9360 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9357 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9355 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9352 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9349 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9347 Acc: 0.4500 \n",
      "val Loss: 1.9388 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9344 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9341 Acc: 0.4500 \n",
      "val Loss: 1.9385 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9338 Acc: 0.4500 \n",
      "val Loss: 1.9383 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9336 Acc: 0.4500 \n",
      "val Loss: 1.9381 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9333 Acc: 0.4500 \n",
      "val Loss: 1.9379 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9330 Acc: 0.4500 \n",
      "val Loss: 1.9378 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9327 Acc: 0.4500 \n",
      "val Loss: 1.9376 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9324 Acc: 0.4500 \n",
      "val Loss: 1.9374 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9322 Acc: 0.4500 \n",
      "val Loss: 1.9372 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9319 Acc: 0.4500 \n",
      "val Loss: 1.9371 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9316 Acc: 0.4500 \n",
      "val Loss: 1.9369 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9313 Acc: 0.4500 \n",
      "val Loss: 1.9367 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9310 Acc: 0.4500 \n",
      "val Loss: 1.9365 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 141 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 142 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 143 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 144 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 145 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 146 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 147 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 148 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 149 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 150 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9386 Acc: 0.4500 \n",
      "val Loss: 1.9413 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9383 Acc: 0.4500 \n",
      "val Loss: 1.9411 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9381 Acc: 0.4500 \n",
      "val Loss: 1.9410 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9378 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9376 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9373 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9370 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9368 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9365 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9362 Acc: 0.4500 \n",
      "val Loss: 1.9398 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9360 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9357 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9354 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9352 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9349 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9346 Acc: 0.4500 \n",
      "val Loss: 1.9388 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9344 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9341 Acc: 0.4500 \n",
      "val Loss: 1.9385 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9338 Acc: 0.4500 \n",
      "val Loss: 1.9383 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9335 Acc: 0.4500 \n",
      "val Loss: 1.9381 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9333 Acc: 0.4500 \n",
      "val Loss: 1.9379 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9330 Acc: 0.4500 \n",
      "val Loss: 1.9378 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9327 Acc: 0.4500 \n",
      "val Loss: 1.9376 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9324 Acc: 0.4500 \n",
      "val Loss: 1.9374 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9321 Acc: 0.4500 \n",
      "val Loss: 1.9372 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9319 Acc: 0.4500 \n",
      "val Loss: 1.9371 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9316 Acc: 0.4500 \n",
      "val Loss: 1.9369 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9313 Acc: 0.4500 \n",
      "val Loss: 1.9367 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9310 Acc: 0.4500 \n",
      "val Loss: 1.9365 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9307 Acc: 0.4500 \n",
      "val Loss: 1.9363 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 151 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 152 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 153 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 154 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 155 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 156 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 157 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 158 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 159 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 160 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9383 Acc: 0.4500 \n",
      "val Loss: 1.9411 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9381 Acc: 0.4500 \n",
      "val Loss: 1.9409 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9378 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9375 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9373 Acc: 0.4500 \n",
      "val Loss: 1.9405 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9370 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9368 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9365 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9362 Acc: 0.4500 \n",
      "val Loss: 1.9398 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9360 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9357 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9354 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9352 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.9349 Acc: 0.4500 \n",
      "val Loss: 1.9390 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9346 Acc: 0.4500 \n",
      "val Loss: 1.9388 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9343 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9341 Acc: 0.4500 \n",
      "val Loss: 1.9384 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9338 Acc: 0.4500 \n",
      "val Loss: 1.9383 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9335 Acc: 0.4500 \n",
      "val Loss: 1.9381 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9332 Acc: 0.4500 \n",
      "val Loss: 1.9379 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9330 Acc: 0.4500 \n",
      "val Loss: 1.9378 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9327 Acc: 0.4500 \n",
      "val Loss: 1.9376 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9324 Acc: 0.4500 \n",
      "val Loss: 1.9374 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9321 Acc: 0.4500 \n",
      "val Loss: 1.9372 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9318 Acc: 0.4500 \n",
      "val Loss: 1.9370 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9316 Acc: 0.4500 \n",
      "val Loss: 1.9369 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9313 Acc: 0.4500 \n",
      "val Loss: 1.9367 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9310 Acc: 0.4500 \n",
      "val Loss: 1.9365 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9307 Acc: 0.4500 \n",
      "val Loss: 1.9363 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9304 Acc: 0.4500 \n",
      "val Loss: 1.9361 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 161 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 162 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 163 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 164 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 165 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 166 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 167 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 168 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 169 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 170 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9381 Acc: 0.4500 \n",
      "val Loss: 1.9409 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9378 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9375 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9373 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9370 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9367 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9365 Acc: 0.4500 \n",
      "val Loss: 1.9400 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9362 Acc: 0.4500 \n",
      "val Loss: 1.9398 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9359 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9357 Acc: 0.4500 \n",
      "val Loss: 1.9395 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9354 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9351 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9349 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9346 Acc: 0.4500 \n",
      "val Loss: 1.9388 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9343 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9341 Acc: 0.4500 \n",
      "val Loss: 1.9384 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9338 Acc: 0.4500 \n",
      "val Loss: 1.9383 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9335 Acc: 0.4500 \n",
      "val Loss: 1.9381 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9332 Acc: 0.4500 \n",
      "val Loss: 1.9379 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9330 Acc: 0.4500 \n",
      "val Loss: 1.9377 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9327 Acc: 0.4500 \n",
      "val Loss: 1.9376 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9324 Acc: 0.4500 \n",
      "val Loss: 1.9374 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9321 Acc: 0.4500 \n",
      "val Loss: 1.9372 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9318 Acc: 0.4500 \n",
      "val Loss: 1.9370 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9315 Acc: 0.4500 \n",
      "val Loss: 1.9369 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9312 Acc: 0.4500 \n",
      "val Loss: 1.9367 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9310 Acc: 0.4500 \n",
      "val Loss: 1.9365 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9307 Acc: 0.4500 \n",
      "val Loss: 1.9363 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9304 Acc: 0.4500 \n",
      "val Loss: 1.9361 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9301 Acc: 0.4500 \n",
      "val Loss: 1.9359 Acc: 0.3415 \n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 171 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 172 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 173 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 174 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 175 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 176 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 177 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 178 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 179 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 180 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9378 Acc: 0.4500 \n",
      "val Loss: 1.9408 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9375 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9373 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9370 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9367 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9365 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9362 Acc: 0.4500 \n",
      "val Loss: 1.9398 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9359 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9357 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9354 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9351 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9349 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9346 Acc: 0.4500 \n",
      "val Loss: 1.9388 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9343 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9340 Acc: 0.4500 \n",
      "val Loss: 1.9384 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9338 Acc: 0.4500 \n",
      "val Loss: 1.9383 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9335 Acc: 0.4500 \n",
      "val Loss: 1.9381 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9332 Acc: 0.4500 \n",
      "val Loss: 1.9379 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9329 Acc: 0.4500 \n",
      "val Loss: 1.9377 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9327 Acc: 0.4500 \n",
      "val Loss: 1.9376 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9324 Acc: 0.4500 \n",
      "val Loss: 1.9374 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9321 Acc: 0.4500 \n",
      "val Loss: 1.9372 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9318 Acc: 0.4500 \n",
      "val Loss: 1.9370 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9315 Acc: 0.4500 \n",
      "val Loss: 1.9368 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9312 Acc: 0.4500 \n",
      "val Loss: 1.9367 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9309 Acc: 0.4500 \n",
      "val Loss: 1.9365 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9307 Acc: 0.4500 \n",
      "val Loss: 1.9363 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9304 Acc: 0.4500 \n",
      "val Loss: 1.9361 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9301 Acc: 0.4500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.9359 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9298 Acc: 0.4500 \n",
      "val Loss: 1.9357 Acc: 0.3415 \n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 181 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 182 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 183 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 184 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 185 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 186 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 187 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 188 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 189 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 190 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9375 Acc: 0.4500 \n",
      "val Loss: 1.9406 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9373 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9370 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9367 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9365 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9362 Acc: 0.4500 \n",
      "val Loss: 1.9398 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9359 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9357 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9354 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9351 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9348 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9346 Acc: 0.4500 \n",
      "val Loss: 1.9388 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9343 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9340 Acc: 0.4500 \n",
      "val Loss: 1.9384 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9338 Acc: 0.4500 \n",
      "val Loss: 1.9382 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9335 Acc: 0.4500 \n",
      "val Loss: 1.9381 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9332 Acc: 0.4500 \n",
      "val Loss: 1.9379 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9329 Acc: 0.4500 \n",
      "val Loss: 1.9377 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9326 Acc: 0.4500 \n",
      "val Loss: 1.9375 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9324 Acc: 0.4500 \n",
      "val Loss: 1.9374 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9321 Acc: 0.4500 \n",
      "val Loss: 1.9372 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9318 Acc: 0.4500 \n",
      "val Loss: 1.9370 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9315 Acc: 0.4500 \n",
      "val Loss: 1.9368 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9312 Acc: 0.4500 \n",
      "val Loss: 1.9367 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9309 Acc: 0.4500 \n",
      "val Loss: 1.9365 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9306 Acc: 0.4500 \n",
      "val Loss: 1.9363 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9303 Acc: 0.4500 \n",
      "val Loss: 1.9361 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9300 Acc: 0.4500 \n",
      "val Loss: 1.9359 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9298 Acc: 0.4500 \n",
      "val Loss: 1.9357 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9295 Acc: 0.4500 \n",
      "val Loss: 1.9355 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n",
      "Epoch generations ( 191 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 192 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 193 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 194 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 195 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 196 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 197 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 198 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 199 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch generations ( 200 /200) :accuracy(fittest mask) tensor(0.4500, dtype=torch.float64) keep_prob 1.0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9373 Acc: 0.4500 \n",
      "val Loss: 1.9404 Acc: 0.3415 \n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9370 Acc: 0.4500 \n",
      "val Loss: 1.9403 Acc: 0.3415 \n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9367 Acc: 0.4500 \n",
      "val Loss: 1.9401 Acc: 0.3415 \n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9364 Acc: 0.4500 \n",
      "val Loss: 1.9399 Acc: 0.3415 \n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9362 Acc: 0.4500 \n",
      "val Loss: 1.9398 Acc: 0.3415 \n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9359 Acc: 0.4500 \n",
      "val Loss: 1.9396 Acc: 0.3415 \n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9356 Acc: 0.4500 \n",
      "val Loss: 1.9394 Acc: 0.3415 \n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9354 Acc: 0.4500 \n",
      "val Loss: 1.9393 Acc: 0.3415 \n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9351 Acc: 0.4500 \n",
      "val Loss: 1.9391 Acc: 0.3415 \n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9348 Acc: 0.4500 \n",
      "val Loss: 1.9389 Acc: 0.3415 \n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9346 Acc: 0.4500 \n",
      "val Loss: 1.9387 Acc: 0.3415 \n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9343 Acc: 0.4500 \n",
      "val Loss: 1.9386 Acc: 0.3415 \n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9340 Acc: 0.4500 \n",
      "val Loss: 1.9384 Acc: 0.3415 \n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9337 Acc: 0.4500 \n",
      "val Loss: 1.9382 Acc: 0.3415 \n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9335 Acc: 0.4500 \n",
      "val Loss: 1.9381 Acc: 0.3415 \n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9332 Acc: 0.4500 \n",
      "val Loss: 1.9379 Acc: 0.3415 \n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9329 Acc: 0.4500 \n",
      "val Loss: 1.9377 Acc: 0.3415 \n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9326 Acc: 0.4500 \n",
      "val Loss: 1.9375 Acc: 0.3415 \n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9323 Acc: 0.4500 \n",
      "val Loss: 1.9374 Acc: 0.3415 \n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9321 Acc: 0.4500 \n",
      "val Loss: 1.9372 Acc: 0.3415 \n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9318 Acc: 0.4500 \n",
      "val Loss: 1.9370 Acc: 0.3415 \n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9315 Acc: 0.4500 \n",
      "val Loss: 1.9368 Acc: 0.3415 \n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9312 Acc: 0.4500 \n",
      "val Loss: 1.9366 Acc: 0.3415 \n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9309 Acc: 0.4500 \n",
      "val Loss: 1.9365 Acc: 0.3415 \n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9306 Acc: 0.4500 \n",
      "val Loss: 1.9363 Acc: 0.3415 \n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9303 Acc: 0.4500 \n",
      "val Loss: 1.9361 Acc: 0.3415 \n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9300 Acc: 0.4500 \n",
      "val Loss: 1.9359 Acc: 0.3415 \n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9297 Acc: 0.4500 \n",
      "val Loss: 1.9357 Acc: 0.3415 \n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9294 Acc: 0.4500 \n",
      "val Loss: 1.9355 Acc: 0.3415 \n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9291 Acc: 0.4500 \n",
      "val Loss: 1.9353 Acc: 0.3415 \n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.341463\n"
     ]
    }
   ],
   "source": [
    "#control block controls the epochs and the generations of mask\n",
    "#step 1 an object of the population class randomly generating the first population \n",
    "#step2 :calculate fitness of each entitiy of the population \n",
    "#step3: creates a mating pool of the population based on the worst two performing parent \n",
    "#step 4 :fittest mask of the generating along with keep_prob found \n",
    "#step 5: if 0th ,10th ,20th, the epochs starts training on the worst performing mask /other wise new generation is created \n",
    "\n",
    "epochgens=0\n",
    "population =Population(mutation_rate,max_population,maskLength)\n",
    "total_acc=[]\n",
    "while (epochgens<=200):\n",
    "    print ('Epoch generations (',epochgens,'/200)',end=' :')\n",
    "    population .calcFitness(model)\n",
    "    population.naturalSelection()\n",
    "    fittestmask,p=population .fittest()\n",
    "    accuracy=fittestmask.fitness(model)\n",
    "    print (\"accuracy(fittest mask)\",accuracy,\"keep_prob\",p,end='\\n')\n",
    "    if (epochgens%10==0):\n",
    "        model,losses,accuracies=train_model(model,criterion,optimizer,fittestmask.gene,p,30)\n",
    "        total_acc=total_acc+accuracies\n",
    "    population.generate()\n",
    "    epochgens+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(range(630),total_acc)\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('proposed')\n",
    "plt.savefig('48_1440...1000/ga_drop1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
